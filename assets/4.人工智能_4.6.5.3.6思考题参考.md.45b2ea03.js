import{_ as a,o as e,c as r,U as t}from"./chunks/framework.489e5108.js";const u=JSON.parse('{"title":"思考题参考","description":"","frontmatter":{},"headers":[],"relativePath":"4.人工智能/4.6.5.3.6思考题参考.md","filePath":"4.人工智能/4.6.5.3.6思考题参考.md","lastUpdated":1696176798000}'),h={name:"4.人工智能/4.6.5.3.6思考题参考.md"},l=t('<h1 id="思考题参考" tabindex="-1">思考题参考 <a class="header-anchor" href="#思考题参考" aria-label="Permalink to &quot;思考题参考&quot;">​</a></h1><p>思考并无绝对的对错，此处仅供参考，希望大家能在自己的思考的基础上再来这里解决思考的疑惑。</p><h2 id="" tabindex="-1"><a class="header-anchor" href="#" aria-label="Permalink to &quot;&quot;">​</a></h2><h2 id="思考-1" tabindex="-1">思考 1 <a class="header-anchor" href="#思考-1" aria-label="Permalink to &quot;思考 1&quot;">​</a></h2><h3 id="_1-1" tabindex="-1">1.1 <a class="header-anchor" href="#_1-1" aria-label="Permalink to &quot;1.1&quot;">​</a></h3><p><a href="https://www.editcode.net/archive/detail/89781" target="_blank" rel="noreferrer">CNN 与 MLP 之间的关系，优缺点</a></p><h3 id="_1-2" tabindex="-1">1.2 <a class="header-anchor" href="#_1-2" aria-label="Permalink to &quot;1.2&quot;">​</a></h3><p><a href="https://blog.csdn.net/weixin_40756000/article/details/117264194" target="_blank" rel="noreferrer">深度理解感受野</a></p><h3 id="_1-3" tabindex="-1">1.3 <a class="header-anchor" href="#_1-3" aria-label="Permalink to &quot;1.3&quot;">​</a></h3><p><a href="https://zhuanlan.zhihu.com/p/382926269" target="_blank" rel="noreferrer">卷积神经网络中的平移不变性</a></p><h3 id="_1-5" tabindex="-1">1.5 <a class="header-anchor" href="#_1-5" aria-label="Permalink to &quot;1.5&quot;">​</a></h3><p><a href="https://zhuanlan.zhihu.com/p/405068757" target="_blank" rel="noreferrer">你真的看懂 Relu 了吗？大家都说是非线性，为什么我怎么看都是线性啊？</a></p><h3 id="_1-6" tabindex="-1">1.6 <a class="header-anchor" href="#_1-6" aria-label="Permalink to &quot;1.6&quot;">​</a></h3><p><a href="https://zhuanlan.zhihu.com/p/140550547" target="_blank" rel="noreferrer">什么是深度学习中的卷积？</a></p><h2 id="思考-2" tabindex="-1">思考 2 <a class="header-anchor" href="#思考-2" aria-label="Permalink to &quot;思考 2&quot;">​</a></h2><h3 id="_2-1" tabindex="-1">2.1 <a class="header-anchor" href="#_2-1" aria-label="Permalink to &quot;2.1&quot;">​</a></h3><p><a href="https://blog.csdn.net/Bulldozer_GD/article/details/95071826" target="_blank" rel="noreferrer">深度学习端到端的理解</a></p><h3 id="_2-2" tabindex="-1">2.2 <a class="header-anchor" href="#_2-2" aria-label="Permalink to &quot;2.2&quot;">​</a></h3><p><a href="https://blog.csdn.net/bestrivern/article/details/89553513" target="_blank" rel="noreferrer">反卷积详解</a></p><h3 id="_2-3" tabindex="-1">2.3 <a class="header-anchor" href="#_2-3" aria-label="Permalink to &quot;2.3&quot;">​</a></h3><h3 id="_2-4" tabindex="-1">2.4 <a class="header-anchor" href="#_2-4" aria-label="Permalink to &quot;2.4&quot;">​</a></h3><p><a href="https://zhuanlan.zhihu.com/p/46200875" target="_blank" rel="noreferrer">语义分割概念及应用介绍</a></p><h2 id="思考-3" tabindex="-1">思考 3 <a class="header-anchor" href="#思考-3" aria-label="Permalink to &quot;思考 3&quot;">​</a></h2><h3 id="_3-1" tabindex="-1">3.1 <a class="header-anchor" href="#_3-1" aria-label="Permalink to &quot;3.1&quot;">​</a></h3><p><a href="https://www.jianshu.com/p/b05282e9ca57" target="_blank" rel="noreferrer">Batch Normalization（BN 层）详解</a></p><h3 id="_3-2" tabindex="-1">3.2 <a class="header-anchor" href="#_3-2" aria-label="Permalink to &quot;3.2&quot;">​</a></h3><p><a href="https://blog.csdn.net/a8039974/article/details/122380735" target="_blank" rel="noreferrer">ResNet 残差、退化等细节解读</a></p>',27),o=[l];function n(i,d,s,_,c,p){return e(),r("div",null,o)}const f=a(h,[["render",n]]);export{u as __pageData,f as default};
