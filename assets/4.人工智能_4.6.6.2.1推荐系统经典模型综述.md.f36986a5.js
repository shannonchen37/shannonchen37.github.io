import{_ as e,o as a,c as n,U as o}from"./chunks/framework.489e5108.js";const f=JSON.parse('{"title":"推荐系统经典模型综述","description":"","frontmatter":{},"headers":[],"relativePath":"4.人工智能/4.6.6.2.1推荐系统经典模型综述.md","filePath":"4.人工智能/4.6.6.2.1推荐系统经典模型综述.md","lastUpdated":1696176798000}'),i={name:"4.人工智能/4.6.6.2.1推荐系统经典模型综述.md"},t=o('<h1 id="推荐系统经典模型综述" tabindex="-1">推荐系统经典模型综述 <a class="header-anchor" href="#推荐系统经典模型综述" aria-label="Permalink to &quot;推荐系统经典模型综述&quot;">​</a></h1><p>Author: 周东霖</p><h1 id="概论" tabindex="-1">概论 <a class="header-anchor" href="#概论" aria-label="Permalink to &quot;概论&quot;">​</a></h1><h2 id="_1-1-摘要" tabindex="-1">1.1 摘要 <a class="header-anchor" href="#_1-1-摘要" aria-label="Permalink to &quot;1.1 摘要&quot;">​</a></h2><p>推荐系统技术最早起源于上世纪末和本世纪初，最早是数据挖掘领域最为经典的应用之一。2012 年至 2015 年，机器学习技术进入推荐系统领域，使得这项古老的应用再次发光发热。 2016 年以来，随着深度学习的发展，大规模算力、大数据的应用的逐渐普及，基于深度学习的推荐系统研究再次成为行业热点，在工业界和学术界都占据极其重要之地。</p><p>本文旨在回顾经典的推荐系统经典模型和研究思路，但并不提供具体的推导方案，并讨论它们各自的优缺点。希望能够为后来入坑者提供一些思路。由于是个人观点陈述，未免存在遗漏和评价不当之嫌，望请见谅。</p><h2 id="_1-2-关键术语" tabindex="-1">1.2 关键术语： <a class="header-anchor" href="#_1-2-关键术语" aria-label="Permalink to &quot;1.2 关键术语：&quot;">​</a></h2><p>Recommender Systems (RS) : 推荐系统</p><p>Information overlaod: 信息过载</p><p>user: 用户</p><p>item: 物品</p><p>feedback: 用户反馈</p><p>explicit feedback: 显式反馈，例如用户评分</p><p>implicit feedback: 隐式反馈，浏览、点击、购买等行为</p><h2 id="_1-3-主要任务" tabindex="-1">1.3 主要任务 <a class="header-anchor" href="#_1-3-主要任务" aria-label="Permalink to &quot;1.3 主要任务&quot;">​</a></h2><p>推荐系统的主要任务包括两方面：</p><p>评分预测 (rating prediction)</p><p>物品推荐 (item recommendation)</p><h2 id="_1-4-评价方式和评价指标" tabindex="-1">1.4 评价方式和评价指标 <a class="header-anchor" href="#_1-4-评价方式和评价指标" aria-label="Permalink to &quot;1.4 评价方式和评价指标&quot;">​</a></h2><p>学术界通常采用离线方式进行评估，一般进行 N 折交叉验证。</p><p>优点：依赖数据集、容易验证和评估；</p><p>缺点：无法直接反映商业需求。</p><p>工业界常采用在线测试，比如 A/B test。</p><p>优点：和商业需求紧密挂钩。</p><p>缺点：成本高、风险大。</p><p>对于评分预测任务，常用评价指标包括：</p><p>Root Mean Squared Error (RMSE) Mean Absolute Error (MAE)</p><p>对于物品推荐任务，常用评价指标包括：</p><p>Precision、Recall、F-measure、Hit Ratio(HR) Average Precision (AP)、Mean Average Precision(MAP) Area Under the ROC Curve (AUC)、Mean Reciprocal Rank (MRR)</p><p>Normalized Discounted Cumulative Gain (NDCG)</p><p>通常情况下，常用 @N 表示推荐前 N 个物品的性能，即 Top-N 推荐。近几年的论文常常采用 HR、NDCG 作为评价指标。</p><h1 id="经典-sota" tabindex="-1">经典 SOTA <a class="header-anchor" href="#经典-sota" aria-label="Permalink to &quot;经典 SOTA&quot;">​</a></h1><h2 id="_2-1-协同过滤-collaborative-filtering-cf" tabindex="-1">2.1 协同过滤（collaborative filtering, CF） <a class="header-anchor" href="#_2-1-协同过滤-collaborative-filtering-cf" aria-label="Permalink to &quot;2.1 协同过滤（collaborative filtering, CF）&quot;">​</a></h2><p>协同过滤是最早的一种推荐系统技术，最早用于电影推荐系统。最早开启这项研究的是明尼苏达大学的研究小组（GroupLens），随后，亚马逊研发了基于物品的协同过滤算法，并开始将 RS 部署上线，正式推向工业界。</p><p>协同过滤的方法主要包括两大类：</p><ul><li>User-based CF: 基于用户的协同过滤 [1]</li><li>Item-based CF: 基于物品的协同过滤 [2,3]</li></ul><h2 id="_2-2-分解模型-factorization-model" tabindex="-1">2.2 分解模型（Factorization model） <a class="header-anchor" href="#_2-2-分解模型-factorization-model" aria-label="Permalink to &quot;2.2 分解模型（Factorization model）&quot;">​</a></h2><p>最早的推荐系统采用的是邻域模型（neighborhood），本质上是计算物品和用户的相似度进行推荐。但是这种方法存在两个致命缺点：</p><ul><li>稀疏性（sparsity）: 实际应用（例如大型电商平台）中，数据非常稀疏，两个用户购买物品存在交集的情况非常少。</li><li>维度灾难：用户向量维度高、物品向量维度高，导致计算成本高，且无法保证准确度。</li></ul><p>由此，分解模型横空出世。最为经典的分解模型就是矩阵分解（Matirx Factorization, MF）[4]。它的理论基础来源于奇异值分解 SVD (Singular Value Decomposition)。 基于 SVD 理论，评分矩阵可被分解成用户和物品的潜在因子，潜在因子的维度 k 远小于用户数量 m 和物品数量 n，由此可以大大降低计算量。(可以看作是后来的 embedding 技术的一个简化版)</p><p>Koren 等人提出 MF 以后，开始在最基础的矩阵分解模型上加入各种辅助信息，并衍生出分解模型的高阶版本，比如 SVD++，TimeSVD++，WRMF，BPR，SLIM 等等。</p><p>其中，特别推荐几个经典模型，它们的一些思想直到今天仍然未过时，也是学习分解模型的必备。</p><ul><li>SVD++[4]：加入了邻域信息之后的矩阵分解</li><li>BPR [5]：采用贝叶斯概率思想，引入隐式反馈优化</li></ul><h2 id="_2-3-高阶分解模型-high-order-factorization-model" tabindex="-1">2.3 高阶分解模型 (high order factorization model) <a class="header-anchor" href="#_2-3-高阶分解模型-high-order-factorization-model" aria-label="Permalink to &quot;2.3 高阶分解模型(high order factorization model)&quot;">​</a></h2><p>矩阵分解模型包括用户和物品两类因子，在处理额外信息比如时间、标签时存在局限。处理额外信息的另一种直接做法是使用张量分解，主要的经典模型包括基于马尔可夫的分解模型 FPMC (Factorizing Personalized Markov Chains)。但是高阶张量分解开销十分巨大，各阶的交互方式不灵活。</p><p>提到高阶分解模型，不得不提推荐系统领域的元老级人物 ——Rendle。他提出的因子分解机模型 ——Factorization machines，几乎杀遍所有数据挖掘竞赛，霸榜 SOTA 数年，引领数年风骚 [6]。FM—— 因子分解机，可以将多种信息进行高阶交互（二阶、三阶等等），但是一般到二阶以后，训练将变得异常困难，计算量也急剧增加。</p><p>当然，高阶分解的另一个相似模型，就是学术界明星 - 华人陈天奇在上海交大读研时提出的 SVDFeature 模型 [7]。在原始论文中，FM 模型称 SVDFeature 模型仅仅是高阶 FM 的一个泛化。</p><p>后来陈天奇赴美留学，将梯度树的性能提升到极致，也就是经典 XGBoost 模型 [8]，也霸榜 SOTA 数年，一时风光无两。SVDFeature 库是上海交大实验室采用 C++ 编写，XGBoost 开源版本很多，建议可以阅读前人开源代码，增加代码能力。同时，在机器学习时代，原版论文涉及很多数学推导和梯度计算，阅读这些论文，也是增进个人内功的很好法门。</p><h2 id="_2-4-深度模型-deep-learning-models" tabindex="-1">2.4 深度模型 (deep-learning models) <a class="header-anchor" href="#_2-4-深度模型-deep-learning-models" aria-label="Permalink to &quot;2.4 深度模型(deep-learning models)&quot;">​</a></h2><p>深度模型进入推荐系统领域大概是 16 年左右，最早将深度模型应用于推荐领域的应用主要是在评论文本挖掘领域。</p><p>评论信息中包含用户偏好、评价等反馈信息。研究者将 CNN 引入推荐系统领域，将文本映射成 word vector，并采用卷积网络训练，将 CNN 和传统的矩阵分解结合，并套上一个概率的外壳进行解释。这方面的工作主要包括 ConvMF [9]、DeepCoNN [10]。</p><p>基于 CNN 的模型主要是应用于评论文本挖掘和可解释性推荐方面，但是这种方法的计算量非常大，并且准确率不高，难以训练。个人认为这种方法仅仅是新奇，并不具备特别大的商业价值。对于推荐这种时效性非常强的应用，训练一个几百亿数量级的文本挖掘模型，却非用于自然语言领域，产生的价值和消耗的资源不成正比。</p><p>何向南在 2017 年提出 NCF，将神经网络结合协同过滤 —— 深度协同过滤，霸榜 SOTA [11]。从此，推荐系统几乎被深度学习攻陷，各种方法层出不穷。他在中科大的团队同时开发了 NeuRec 开源框架 —— 一个基于 Tensorflow 的推荐框架，适合新手入门。</p><p>在工业界方面，最早将深度学习应用于推荐系统领域的是 YouTobe，它的大规模推荐系统分成两步 —— 排序和召回。排序阶段是初排，将百万级别数量级的物品进行排序，选出几百个候选物品；召回阶段是精排，根据物品特征和用户偏好对几百个物品进行细粒度排序。</p><h2 id="_2-5-序列推荐-sequential-recommender" tabindex="-1">2.5 序列推荐 (sequential recommender) <a class="header-anchor" href="#_2-5-序列推荐-sequential-recommender" aria-label="Permalink to &quot;2.5 序列推荐(sequential recommender)&quot;">​</a></h2><p>前面介绍了机器学习时代的几种经典模型，接下来介绍深度序列推荐。Session based SRs 是会话推荐，Sequential recommender 是序列推荐。前者是指一个用户在一个 session 当中的点击序列，而后者更关注于物品序列顺序本身，而与用户无关。但是两者之间有着非常相似而密切的联系。</p><p>最早开始将深度引入会话推荐的模型是 GRU4Rec [12]，它直接将 RNNs 用于会话推荐系统，并采用 zero-padding 补齐序列长度不一致的问题。实际上，Padding 是常见的序列补齐技术，但是值得注意的是，有些开源代码采用的是左补齐（在序列的左边补齐，如 RecBole），有些采用的是右补齐（如 GRU4Rec，SASRec）。</p><p>2018 年的 ICDM 顶会上，加州大学圣地亚哥分校的 McAuley 团队（推荐系统领域的又一个大牛）提出的 SASRec [13]，直接将注意力机制用于序列推荐，完成 SOTA。原论文的实验部分设置十分精彩，值得论文初写者模仿和借鉴。</p><p>从此以后，基于 attention-based 的模型开始百花齐放，比如加入物品序列和物品特征序列的双路注意力 FDSA [14]、使用双向注意力机制的 BERT4Rec [15] 等等。</p><p>20 年以来，由于图神经的方法渐渐成为研究热点。基于图网络的推荐系统也引起了学术界的兴趣。SR-GNN [16] 是最近将 GNN 的方法用于会话推荐系统。随后，各种图方法开始爆发，目前主流的图神经网络方法包括清华大学和快手联合推出的 SURGE [17]。</p><h1 id="主要会议和期刊" tabindex="-1">主要会议和期刊 <a class="header-anchor" href="#主要会议和期刊" aria-label="Permalink to &quot;主要会议和期刊&quot;">​</a></h1><ul><li>ACM Conference on Recommender System (RecSys)： 推荐系统顶会</li><li>ACM SIGKDD International Conference on Knowledge Discovery and Data Mining. KDD 竞赛，数据挖掘顶会</li><li>IEEE International Conference on Data Mining : ICDM，数据挖掘顶会</li><li>International Joint Conference on Artificial Intelligence: IJCAI</li><li><strong>ACM the Web Conference</strong>: 3W</li><li><strong>ACM International Conference on Web Search and Data Mining</strong>:WSDM</li><li><strong>ACM International Conference on Informaiton and Knowledge Management</strong>:CIKM</li></ul><h1 id="国内外大牛-follow" tabindex="-1">国内外大牛 Follow <a class="header-anchor" href="#国内外大牛-follow" aria-label="Permalink to &quot;国内外大牛 Follow&quot;">​</a></h1><ul><li>Koren: 矩阵分解模型提出者，2009 年 Netflix prize 获得者</li><li>Steffen Rendle: FM 系列提出者，工业界推荐系统大牛</li><li>何向南：中科大教授，NUS 博士，百万青橙奖得主，国内学术界推荐大牛，开源 NeuRec</li><li>McAuley：加州大学圣地亚哥分校教授，北美推荐系统领域大牛，SASRec 模型</li><li>赵鑫：中国人民大学教授，联合开发 Recbole 开源库</li></ul><h1 id="参考文献" tabindex="-1">参考文献 <a class="header-anchor" href="#参考文献" aria-label="Permalink to &quot;参考文献&quot;">​</a></h1><p>[1]Breese et al. 1998. Empirical analysis of predictive algorithms for collaborative filtering. In Proceedings of the Fourteenth conference on Uncertainty in artificial intelligence (UAI&#39;98), 43–52.</p><p>[2]G. Linden J. Jacobi and E. Benson, Collaborative Recommendations Using Item-to Item Similarity Mappings, US Patent 6,266,649 (to Amazon.com), Patent and Trademark Office, Washington, D.C., 2001</p><p>[3]Sarwar et al., Item-based collaborative filtering recommendation algorithms, Proceedings of the 10th international conference on World Wide Web, p.285-295, May 01-05, 2001, Hong Kong</p><p>[4] Koren, Y. 2008. Factorization meets the neighborhood: A multifaceted collaborative filtering model [C]. Proceedings of the 14th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining. KDD ’08. Las Vegas, Nevada, USA: ACM, 426–434</p><p>[5] Rendle, S., Freudenthaler, C., Gantner, Z., and Schmidt-Thieme, L. 2009b. Bpr: Bayesian personalized ranking from implicit feedback [C]. Proceedings of the Twenty-Fifth Conference on Uncertainty in Artificial Intelligence. UAI ’09. Montreal, Quebec, Canada, 452–461.</p><p>[6] Rendle, S. 2013. Scaling factorization machines to relational data [C]. Proceedings of the 39th International Conference on Very Large Data Bases. volume 6 of Proc. VLDB Endow. Riva del Garda, Trento, Italy: VLDB Endowment, 337–348.</p><p>[7] Chen, T., Zhang, W., Lu, Q., Chen, K., Zheng, Z., and Yu, Y. 2012c. Svdfeature: a toolkit for feature-based collaborative filtering [J]. The Journal of Machine Learning Research, 13(1):3585–3588</p><p>[8] Chen, Tianqi, and Carlos Guestrin. &quot;Xgboost: A scalable tree boosting system.&quot; Proceedings of the 22nd acm sigkdd international conference on knowledge discovery and data mining. 2016.</p><p>[9]Kim, Donghyun, et al. &quot;Convolutional matrix factorization for document context-aware recommendation.&quot; Proceedings of the 10th ACM conference on recommender systems. 2016.</p><p>[10]Zheng, Lei, Vahid Noroozi, and Philip S. Yu. &quot;Joint deep modeling of users and items using reviews for recommendation.&quot; Proceedings of the tenth ACM international conference on web search and data mining. 2017.</p><p>[11]He, Xiangnan, et al. &quot;Neural collaborative filtering.&quot; Proceedings of the 26th international conference on world wide web. 2017.</p><p>[12] Hidasi, Balázs, et al. &quot;Session-based recommendations with recurrent neural networks.&quot; arXiv preprint arXiv:1511.06939 (2015)</p><p>[13] Kang, Wang-Cheng, and Julian McAuley. &quot;Self-attentive sequential recommendation.&quot; 2018 IEEE International Conference on Data Mining (ICDM). IEEE, 2018.</p><p>[14] Tingting Zhang, Pengpeng Zhao et al. Feature-level Deeper Self-Attention Network for Sequential Recommendation.2019.</p><p>[15]Fei Sun, Jun Liu et al. BERT4Rec: Sequential Recommendation with Bidirectional Encoder Representations from Transformer.2019.</p><p>[16]Shu Wu, Yuyuan Tang, Yanqiao Zhu, Liang Wang, Xing Xie, Tieniu Tan. Session-based Recommendation with Graph Neural Networks. 2019.</p><p>[17]Jianxin et al., Sequential Recommendation with Graph Neural Networks. SIGIR 2021.</p>',82),r=[t];function l(c,d,p,s,h,m){return a(),n("div",null,r)}const g=e(i,[["render",l]]);export{f as __pageData,g as default};
