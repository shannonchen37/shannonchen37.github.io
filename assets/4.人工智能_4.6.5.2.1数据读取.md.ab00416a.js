import{_ as s,o as a,c as n,U as l}from"./chunks/framework.489e5108.js";const F=JSON.parse('{"title":"数据读取","description":"","frontmatter":{},"headers":[],"relativePath":"4.人工智能/4.6.5.2.1数据读取.md","filePath":"4.人工智能/4.6.5.2.1数据读取.md","lastUpdated":1696176798000}'),p={name:"4.人工智能/4.6.5.2.1数据读取.md"},e=l(`<h1 id="数据读取" tabindex="-1">数据读取 <a class="header-anchor" href="#数据读取" aria-label="Permalink to &quot;数据读取&quot;">​</a></h1><p>Torchvision 中默认使用的图像加载器是 PIL，因此为了确保 Torchvision 正常运行，我们还需要安装一个 Python 的第三方图像处理库 ——Pillow 库。Pillow 提供了广泛的文件格式支持，强大的图像处理能力，主要包括图像储存、图像显示、格式转换以及基本的图像处理操作等。</p><p>我们先介绍 Torchvision 的常用数据集及其读取方法。</p><p>PyTorch 为我们提供了一种十分方便的数据读取机制，即使用 Dataset 类与 DataLoader 类的组合，来得到数据迭代器。在训练或预测时，数据迭代器能够输出每一批次所需的数据，并且对数据进行相应的预处理与数据增强操作。</p><p>下面我们分别来看下 Dataset 类与 DataLoader 类。</p><h1 id="dataset-类" tabindex="-1">Dataset 类 <a class="header-anchor" href="#dataset-类" aria-label="Permalink to &quot;Dataset 类&quot;">​</a></h1><p>PyTorch 中的 Dataset 类是一个抽象类，它可以用来表示数据集。我们通过继承 Dataset 类来自定义数据集的格式、大小和其它属性，后面就可以供 DataLoader 类直接使用。</p><p>其实这就表示，无论使用自定义的数据集，还是官方为我们封装好的数据集，其本质都是继承了 Dataset 类。而在继承 Dataset 类时，至少需要重写以下几个方法：</p><ul><li><strong>init</strong> ()：构造函数，可自定义数据读取方法以及进行数据预处理；</li><li><strong>len</strong> ()：返回数据集大小；</li><li><strong>getitem</strong> ()：索引数据集中的某一个数据。</li></ul><p>下面我们来编写一个简单的例子，看下如何使用 Dataset 类定义一个 Tensor 类型的数据集。</p><div class="language-python vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki github-dark vp-code-dark"><code><span class="line"><span style="color:#F97583;">import</span><span style="color:#E1E4E8;"> torch</span></span>
<span class="line"><span style="color:#F97583;">from</span><span style="color:#E1E4E8;"> torch.utils.data </span><span style="color:#F97583;">import</span><span style="color:#E1E4E8;"> Dataset</span></span>
<span class="line"></span>
<span class="line"><span style="color:#F97583;">class</span><span style="color:#E1E4E8;"> </span><span style="color:#B392F0;">MyDataset</span><span style="color:#E1E4E8;">(</span><span style="color:#B392F0;">Dataset</span><span style="color:#E1E4E8;">):</span></span>
<span class="line"><span style="color:#E1E4E8;">    </span><span style="color:#6A737D;"># 构造函数</span></span>
<span class="line"><span style="color:#E1E4E8;">    </span><span style="color:#F97583;">def</span><span style="color:#E1E4E8;"> </span><span style="color:#79B8FF;">__init__</span><span style="color:#E1E4E8;">(self, data_tensor, target_tensor):</span></span>
<span class="line"><span style="color:#E1E4E8;">        </span><span style="color:#79B8FF;">self</span><span style="color:#E1E4E8;">.data_tensor </span><span style="color:#F97583;">=</span><span style="color:#E1E4E8;"> data_tensor</span></span>
<span class="line"><span style="color:#E1E4E8;">        </span><span style="color:#79B8FF;">self</span><span style="color:#E1E4E8;">.target_tensor </span><span style="color:#F97583;">=</span><span style="color:#E1E4E8;"> target_tensor</span></span>
<span class="line"><span style="color:#E1E4E8;">    </span><span style="color:#6A737D;"># 返回数据集大小</span></span>
<span class="line"><span style="color:#E1E4E8;">    </span><span style="color:#F97583;">def</span><span style="color:#E1E4E8;"> </span><span style="color:#79B8FF;">__len__</span><span style="color:#E1E4E8;">(self):</span></span>
<span class="line"><span style="color:#E1E4E8;">        </span><span style="color:#F97583;">return</span><span style="color:#E1E4E8;"> </span><span style="color:#79B8FF;">self</span><span style="color:#E1E4E8;">.data_tensor.size(</span><span style="color:#79B8FF;">0</span><span style="color:#E1E4E8;">)</span></span>
<span class="line"><span style="color:#E1E4E8;">    </span><span style="color:#6A737D;"># 返回索引的数据与标签</span></span>
<span class="line"><span style="color:#E1E4E8;">    </span><span style="color:#F97583;">def</span><span style="color:#E1E4E8;"> </span><span style="color:#79B8FF;">__getitem__</span><span style="color:#E1E4E8;">(self, index):</span></span>
<span class="line"><span style="color:#E1E4E8;">        </span><span style="color:#F97583;">return</span><span style="color:#E1E4E8;"> </span><span style="color:#79B8FF;">self</span><span style="color:#E1E4E8;">.data_tensor[index], </span><span style="color:#79B8FF;">self</span><span style="color:#E1E4E8;">.target_tensor[index]</span></span>
<span class="line"><span style="color:#E1E4E8;"> </span><span style="color:#9ECBFF;">&#39;&#39;&#39;</span></span>
<span class="line"><span style="color:#9ECBFF;"> 我们定义了一个名字为 MyDataset 的数据集，在构造函数中，传入 Tensor 类型的数据与标签；</span></span>
<span class="line"><span style="color:#9ECBFF;"> 在 __len__ 函数中，直接返回 Tensor 的大小；在 __getitem__ 函数中返回索引的数据与标签。</span></span>
<span class="line"><span style="color:#9ECBFF;"> &#39;&#39;&#39;</span></span></code></pre><pre class="shiki github-light vp-code-light"><code><span class="line"><span style="color:#D73A49;">import</span><span style="color:#24292E;"> torch</span></span>
<span class="line"><span style="color:#D73A49;">from</span><span style="color:#24292E;"> torch.utils.data </span><span style="color:#D73A49;">import</span><span style="color:#24292E;"> Dataset</span></span>
<span class="line"></span>
<span class="line"><span style="color:#D73A49;">class</span><span style="color:#24292E;"> </span><span style="color:#6F42C1;">MyDataset</span><span style="color:#24292E;">(</span><span style="color:#6F42C1;">Dataset</span><span style="color:#24292E;">):</span></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#6A737D;"># 构造函数</span></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#D73A49;">def</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">__init__</span><span style="color:#24292E;">(self, data_tensor, target_tensor):</span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#005CC5;">self</span><span style="color:#24292E;">.data_tensor </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> data_tensor</span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#005CC5;">self</span><span style="color:#24292E;">.target_tensor </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> target_tensor</span></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#6A737D;"># 返回数据集大小</span></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#D73A49;">def</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">__len__</span><span style="color:#24292E;">(self):</span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#D73A49;">return</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">self</span><span style="color:#24292E;">.data_tensor.size(</span><span style="color:#005CC5;">0</span><span style="color:#24292E;">)</span></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#6A737D;"># 返回索引的数据与标签</span></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#D73A49;">def</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">__getitem__</span><span style="color:#24292E;">(self, index):</span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#D73A49;">return</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">self</span><span style="color:#24292E;">.data_tensor[index], </span><span style="color:#005CC5;">self</span><span style="color:#24292E;">.target_tensor[index]</span></span>
<span class="line"><span style="color:#24292E;"> </span><span style="color:#032F62;">&#39;&#39;&#39;</span></span>
<span class="line"><span style="color:#032F62;"> 我们定义了一个名字为 MyDataset 的数据集，在构造函数中，传入 Tensor 类型的数据与标签；</span></span>
<span class="line"><span style="color:#032F62;"> 在 __len__ 函数中，直接返回 Tensor 的大小；在 __getitem__ 函数中返回索引的数据与标签。</span></span>
<span class="line"><span style="color:#032F62;"> &#39;&#39;&#39;</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br></div></div><p>然后我们来看一下如何调用刚才定义的数据集。首先随机生成一个 10*3 维的数据 Tensor，然后生成 10 维的标签 Tensor，与数据 Tensor 相对应。利用这两个 Tensor，生成一个 MyDataset 的对象。查看数据集的大小可以直接用 len () 函数，索引调用数据可以直接使用下标。</p><div class="language-python vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki github-dark vp-code-dark"><code><span class="line"><span style="color:#6A737D;"># 生成数据</span></span>
<span class="line"><span style="color:#E1E4E8;">data_tensor </span><span style="color:#F97583;">=</span><span style="color:#E1E4E8;"> torch.randn(</span><span style="color:#79B8FF;">10</span><span style="color:#E1E4E8;">, </span><span style="color:#79B8FF;">3</span><span style="color:#E1E4E8;">)</span></span>
<span class="line"><span style="color:#E1E4E8;">target_tensor </span><span style="color:#F97583;">=</span><span style="color:#E1E4E8;"> torch.randint(</span><span style="color:#79B8FF;">2</span><span style="color:#E1E4E8;">, (</span><span style="color:#79B8FF;">10</span><span style="color:#E1E4E8;">,)) </span><span style="color:#6A737D;"># 标签是0或1</span></span>
<span class="line"><span style="color:#6A737D;"># 生成10个随机数，随机数的范围只能是0或者1</span></span>
<span class="line"></span>
<span class="line"><span style="color:#6A737D;"># 将数据封装成Dataset</span></span>
<span class="line"><span style="color:#E1E4E8;">my_dataset </span><span style="color:#F97583;">=</span><span style="color:#E1E4E8;"> MyDataset(data_tensor, target_tensor)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#6A737D;"># 查看数据集大小</span></span>
<span class="line"><span style="color:#79B8FF;">print</span><span style="color:#E1E4E8;">(</span><span style="color:#9ECBFF;">&#39;Dataset size:&#39;</span><span style="color:#E1E4E8;">, </span><span style="color:#79B8FF;">len</span><span style="color:#E1E4E8;">(my_dataset))</span></span>
<span class="line"></span>
<span class="line"><span style="color:#6A737D;"># 使用索引调用数据</span></span>
<span class="line"><span style="color:#79B8FF;">print</span><span style="color:#E1E4E8;">(</span><span style="color:#9ECBFF;">&#39;tensor_data[0]: &#39;</span><span style="color:#E1E4E8;">, my_dataset[</span><span style="color:#79B8FF;">0</span><span style="color:#E1E4E8;">])</span></span></code></pre><pre class="shiki github-light vp-code-light"><code><span class="line"><span style="color:#6A737D;"># 生成数据</span></span>
<span class="line"><span style="color:#24292E;">data_tensor </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> torch.randn(</span><span style="color:#005CC5;">10</span><span style="color:#24292E;">, </span><span style="color:#005CC5;">3</span><span style="color:#24292E;">)</span></span>
<span class="line"><span style="color:#24292E;">target_tensor </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> torch.randint(</span><span style="color:#005CC5;">2</span><span style="color:#24292E;">, (</span><span style="color:#005CC5;">10</span><span style="color:#24292E;">,)) </span><span style="color:#6A737D;"># 标签是0或1</span></span>
<span class="line"><span style="color:#6A737D;"># 生成10个随机数，随机数的范围只能是0或者1</span></span>
<span class="line"></span>
<span class="line"><span style="color:#6A737D;"># 将数据封装成Dataset</span></span>
<span class="line"><span style="color:#24292E;">my_dataset </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> MyDataset(data_tensor, target_tensor)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#6A737D;"># 查看数据集大小</span></span>
<span class="line"><span style="color:#005CC5;">print</span><span style="color:#24292E;">(</span><span style="color:#032F62;">&#39;Dataset size:&#39;</span><span style="color:#24292E;">, </span><span style="color:#005CC5;">len</span><span style="color:#24292E;">(my_dataset))</span></span>
<span class="line"></span>
<span class="line"><span style="color:#6A737D;"># 使用索引调用数据</span></span>
<span class="line"><span style="color:#005CC5;">print</span><span style="color:#24292E;">(</span><span style="color:#032F62;">&#39;tensor_data[0]: &#39;</span><span style="color:#24292E;">, my_dataset[</span><span style="color:#005CC5;">0</span><span style="color:#24292E;">])</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br></div></div><h1 id="dataloader-类" tabindex="-1">DataLoader 类 <a class="header-anchor" href="#dataloader-类" aria-label="Permalink to &quot;DataLoader 类&quot;">​</a></h1><p>在实际项目中，如果数据量很大，考虑到内存有限、I/O 速度等问题，在训练过程中不可能一次性的将所有数据全部加载到内存中，也不能只用一个进程去加载，所以就需要多进程、迭代加载，而 DataLoader 就是基于这些需要被设计出来的。</p><p>DataLoader 是一个迭代器，最基本的使用方法就是传入一个 Dataset 对象，它会根据参数 batch_size 的值生成一个 batch 的数据，节省内存的同时，它还可以实现多进程、数据打乱等处理。</p><p>DataLoader 类的调用方式如下：</p><div class="language-python vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki github-dark vp-code-dark"><code><span class="line"><span style="color:#F97583;">from</span><span style="color:#E1E4E8;"> torch.utils.data </span><span style="color:#F97583;">import</span><span style="color:#E1E4E8;"> DataLoader</span></span>
<span class="line"><span style="color:#E1E4E8;">tensor_dataloader </span><span style="color:#F97583;">=</span><span style="color:#E1E4E8;"> DataLoader(</span><span style="color:#FFAB70;">dataset</span><span style="color:#F97583;">=</span><span style="color:#E1E4E8;">my_dataset, </span><span style="color:#6A737D;"># 传入的数据集, 必须参数</span></span>
<span class="line"><span style="color:#E1E4E8;">                               </span><span style="color:#FFAB70;">batch_size</span><span style="color:#F97583;">=</span><span style="color:#79B8FF;">2</span><span style="color:#E1E4E8;">,       </span><span style="color:#6A737D;"># 输出的batch大小</span></span>
<span class="line"><span style="color:#E1E4E8;">                               </span><span style="color:#FFAB70;">shuffle</span><span style="color:#F97583;">=</span><span style="color:#79B8FF;">True</span><span style="color:#E1E4E8;">,       </span><span style="color:#6A737D;"># 数据是否打乱</span></span>
<span class="line"><span style="color:#E1E4E8;">                               </span><span style="color:#FFAB70;">num_workers</span><span style="color:#F97583;">=</span><span style="color:#79B8FF;">0</span><span style="color:#E1E4E8;">)      </span><span style="color:#6A737D;"># 进程数, 0表示只有主进程</span></span>
<span class="line"></span>
<span class="line"><span style="color:#6A737D;"># 以循环形式输出</span></span>
<span class="line"><span style="color:#F97583;">for</span><span style="color:#E1E4E8;"> data, target </span><span style="color:#F97583;">in</span><span style="color:#E1E4E8;"> tensor_dataloader: </span></span>
<span class="line"><span style="color:#E1E4E8;">    </span><span style="color:#79B8FF;">print</span><span style="color:#E1E4E8;">(data, target)</span></span>
<span class="line"><span style="color:#9ECBFF;">&#39;&#39;&#39;</span></span>
<span class="line"><span style="color:#9ECBFF;">输出:</span></span>
<span class="line"><span style="color:#9ECBFF;">tensor([[-0.1781, -1.1019, -0.1507],</span></span>
<span class="line"><span style="color:#9ECBFF;">        [-0.6170,  0.2366,  0.1006]]) tensor([0, 0])</span></span>
<span class="line"><span style="color:#9ECBFF;">tensor([[ 0.9451, -0.4923, -1.8178],</span></span>
<span class="line"><span style="color:#9ECBFF;">        [-0.4046, -0.5436, -1.7911]]) tensor([0, 0])</span></span>
<span class="line"><span style="color:#9ECBFF;">tensor([[-0.4561, -1.2480, -0.3051],</span></span>
<span class="line"><span style="color:#9ECBFF;">        [-0.9738,  0.9465,  0.4812]]) tensor([1, 0])</span></span>
<span class="line"><span style="color:#9ECBFF;">tensor([[ 0.0260,  1.5276,  0.1687],</span></span>
<span class="line"><span style="color:#9ECBFF;">        [ 1.3692, -0.0170, -1.6831]]) tensor([1, 0])</span></span>
<span class="line"><span style="color:#9ECBFF;">tensor([[ 0.0515, -0.8892, -0.1699],</span></span>
<span class="line"><span style="color:#9ECBFF;">        [ 0.4931, -0.0697,  0.4171]]) tensor([1, 0])</span></span>
<span class="line"><span style="color:#9ECBFF;">&#39;&#39;&#39;</span></span>
<span class="line"><span style="color:#E1E4E8;"> </span></span>
<span class="line"><span style="color:#6A737D;"># 输出一个batch(用iter()强制类型转换成迭代器的对象，next()是输出迭代器下一个元素)</span></span>
<span class="line"><span style="color:#79B8FF;">print</span><span style="color:#E1E4E8;">(</span><span style="color:#9ECBFF;">&#39;One batch tensor data: &#39;</span><span style="color:#E1E4E8;">, </span><span style="color:#79B8FF;">iter</span><span style="color:#E1E4E8;">(tensor_dataloader).next())</span></span>
<span class="line"><span style="color:#9ECBFF;">&#39;&#39;&#39;</span></span>
<span class="line"><span style="color:#9ECBFF;">输出:</span></span>
<span class="line"><span style="color:#9ECBFF;">One batch tensor data:  [tensor([[ 0.9451, -0.4923, -1.8178],</span></span>
<span class="line"><span style="color:#9ECBFF;">        [-0.4046, -0.5436, -1.7911]]), tensor([0, 0])]</span></span>
<span class="line"><span style="color:#9ECBFF;">&#39;&#39;&#39;</span></span></code></pre><pre class="shiki github-light vp-code-light"><code><span class="line"><span style="color:#D73A49;">from</span><span style="color:#24292E;"> torch.utils.data </span><span style="color:#D73A49;">import</span><span style="color:#24292E;"> DataLoader</span></span>
<span class="line"><span style="color:#24292E;">tensor_dataloader </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> DataLoader(</span><span style="color:#E36209;">dataset</span><span style="color:#D73A49;">=</span><span style="color:#24292E;">my_dataset, </span><span style="color:#6A737D;"># 传入的数据集, 必须参数</span></span>
<span class="line"><span style="color:#24292E;">                               </span><span style="color:#E36209;">batch_size</span><span style="color:#D73A49;">=</span><span style="color:#005CC5;">2</span><span style="color:#24292E;">,       </span><span style="color:#6A737D;"># 输出的batch大小</span></span>
<span class="line"><span style="color:#24292E;">                               </span><span style="color:#E36209;">shuffle</span><span style="color:#D73A49;">=</span><span style="color:#005CC5;">True</span><span style="color:#24292E;">,       </span><span style="color:#6A737D;"># 数据是否打乱</span></span>
<span class="line"><span style="color:#24292E;">                               </span><span style="color:#E36209;">num_workers</span><span style="color:#D73A49;">=</span><span style="color:#005CC5;">0</span><span style="color:#24292E;">)      </span><span style="color:#6A737D;"># 进程数, 0表示只有主进程</span></span>
<span class="line"></span>
<span class="line"><span style="color:#6A737D;"># 以循环形式输出</span></span>
<span class="line"><span style="color:#D73A49;">for</span><span style="color:#24292E;"> data, target </span><span style="color:#D73A49;">in</span><span style="color:#24292E;"> tensor_dataloader: </span></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#005CC5;">print</span><span style="color:#24292E;">(data, target)</span></span>
<span class="line"><span style="color:#032F62;">&#39;&#39;&#39;</span></span>
<span class="line"><span style="color:#032F62;">输出:</span></span>
<span class="line"><span style="color:#032F62;">tensor([[-0.1781, -1.1019, -0.1507],</span></span>
<span class="line"><span style="color:#032F62;">        [-0.6170,  0.2366,  0.1006]]) tensor([0, 0])</span></span>
<span class="line"><span style="color:#032F62;">tensor([[ 0.9451, -0.4923, -1.8178],</span></span>
<span class="line"><span style="color:#032F62;">        [-0.4046, -0.5436, -1.7911]]) tensor([0, 0])</span></span>
<span class="line"><span style="color:#032F62;">tensor([[-0.4561, -1.2480, -0.3051],</span></span>
<span class="line"><span style="color:#032F62;">        [-0.9738,  0.9465,  0.4812]]) tensor([1, 0])</span></span>
<span class="line"><span style="color:#032F62;">tensor([[ 0.0260,  1.5276,  0.1687],</span></span>
<span class="line"><span style="color:#032F62;">        [ 1.3692, -0.0170, -1.6831]]) tensor([1, 0])</span></span>
<span class="line"><span style="color:#032F62;">tensor([[ 0.0515, -0.8892, -0.1699],</span></span>
<span class="line"><span style="color:#032F62;">        [ 0.4931, -0.0697,  0.4171]]) tensor([1, 0])</span></span>
<span class="line"><span style="color:#032F62;">&#39;&#39;&#39;</span></span>
<span class="line"><span style="color:#24292E;"> </span></span>
<span class="line"><span style="color:#6A737D;"># 输出一个batch(用iter()强制类型转换成迭代器的对象，next()是输出迭代器下一个元素)</span></span>
<span class="line"><span style="color:#005CC5;">print</span><span style="color:#24292E;">(</span><span style="color:#032F62;">&#39;One batch tensor data: &#39;</span><span style="color:#24292E;">, </span><span style="color:#005CC5;">iter</span><span style="color:#24292E;">(tensor_dataloader).next())</span></span>
<span class="line"><span style="color:#032F62;">&#39;&#39;&#39;</span></span>
<span class="line"><span style="color:#032F62;">输出:</span></span>
<span class="line"><span style="color:#032F62;">One batch tensor data:  [tensor([[ 0.9451, -0.4923, -1.8178],</span></span>
<span class="line"><span style="color:#032F62;">        [-0.4046, -0.5436, -1.7911]]), tensor([0, 0])]</span></span>
<span class="line"><span style="color:#032F62;">&#39;&#39;&#39;</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br><span class="line-number">21</span><br><span class="line-number">22</span><br><span class="line-number">23</span><br><span class="line-number">24</span><br><span class="line-number">25</span><br><span class="line-number">26</span><br><span class="line-number">27</span><br><span class="line-number">28</span><br><span class="line-number">29</span><br><span class="line-number">30</span><br></div></div><p>结合代码，我们梳理一下 DataLoader 中的几个参数，它们分别表示：</p><ul><li>dataset：Dataset 类型，输入的数据集，必须参数；</li><li>batch_size：int 类型，每个 batch 有多少个样本；</li><li>shuffle：bool 类型，在每个 epoch 开始的时候，是否对数据进行重新打乱；</li><li>num_workers：int 类型，加载数据的进程数，0 意味着所有的数据都会被加载进主进程，默认为 0。</li></ul><p><strong>思考题</strong></p><p>按照上述代码，One batch tensor data 的输出是否正确，若不正确，为什么？</p><h1 id="利用-torchvision-读取数据" tabindex="-1">利用 Torchvision 读取数据 <a class="header-anchor" href="#利用-torchvision-读取数据" aria-label="Permalink to &quot;利用 Torchvision 读取数据&quot;">​</a></h1><p>Torchvision 库中的 torchvision.datasets 包中提供了丰富的图像数据集的接口。常用的图像数据集，例如 MNIST、COCO 等，这个模块都为我们做了相应的封装。</p><p>下表中列出了 torchvision.datasets 包所有支持的数据集。各个数据集的说明与接口，详见链接 <a href="https://pytorch.org/vision/stable/datasets.html" target="_blank" rel="noreferrer">https://pytorch.org/vision/stable/datasets.html</a>。</p><p><img src="https://cdn.xyxsw.site/boxcnxvqC7FKt1qeCZoI2kVf9yg.png" alt=""></p><p>注意，torchvision.datasets 这个包本身并不包含数据集的文件本身，它的工作方式是先从网络上把数据集下载到用户指定目录，然后再用它的加载器把数据集加载到内存中。最后，把这个加载后的数据集作为对象返回给用户。</p><p>为了让你进一步加深对知识的理解，我们以 MNIST 数据集为例，来说明一下这个模块具体的使用方法。</p><h1 id="mnist-数据集简介" tabindex="-1">MNIST 数据集简介 <a class="header-anchor" href="#mnist-数据集简介" aria-label="Permalink to &quot;MNIST 数据集简介&quot;">​</a></h1><p>MNIST 数据集是一个著名的手写数字数据集，因为上手简单，在深度学习领域，手写数字识别是一个很经典的学习入门样例。</p><p>MNIST 数据集是 NIST 数据集的一个子集，MNIST 数据集你可以通过<a href="http://yann.lecun.com/exdb/mnist/" target="_blank" rel="noreferrer">这里</a>下载。它包含了四个部分。</p><p><img src="https://cdn.xyxsw.site/boxcnCP2Sp932nPy8Il5Z5d4Aih.png" alt=""></p><p>MNIST 数据集是 ubyte 格式存储，我们先将 “训练集图片” 解析成图片格式，来直观地看一看数据集具体是什么样子的。具体怎么解析，我们在后面数据预览再展开。</p><p><img src="https://cdn.xyxsw.site/boxcnjsG31hhjqdxOnoCGFGR6sh.png" alt=""></p><p>接下来，我们看一下如何使用 Torchvision 来读取 MNIST 数据集。</p><p>对于 torchvision.datasets 所支持的所有数据集，它都内置了相应的数据集接口。例如刚才介绍的 MNIST 数据集，torchvision.datasets 就有一个 MNIST 的接口，接口内封装了从下载、解压缩、读取数据、解析数据等全部过程。</p><p>这些接口的工作方式差不多，都是先从网络上把数据集下载到指定目录，然后再用加载器把数据集加载到内存中，最后将加载后的数据集作为对象返回给用户。</p><p>以 MNIST 为例，我们可以用如下方式调用：</p><div class="language-python vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki github-dark vp-code-dark"><code><span class="line"><span style="color:#6A737D;"># 以MNIST为例</span></span>
<span class="line"><span style="color:#F97583;">import</span><span style="color:#E1E4E8;"> torchvision</span></span>
<span class="line"><span style="color:#E1E4E8;">mnist_dataset </span><span style="color:#F97583;">=</span><span style="color:#E1E4E8;"> torchvision.datasets.MNIST(</span><span style="color:#FFAB70;">root</span><span style="color:#F97583;">=</span><span style="color:#9ECBFF;">&#39;./data&#39;</span><span style="color:#E1E4E8;">,</span></span>
<span class="line"><span style="color:#E1E4E8;">                                       </span><span style="color:#FFAB70;">train</span><span style="color:#F97583;">=</span><span style="color:#79B8FF;">True</span><span style="color:#E1E4E8;">,</span></span>
<span class="line"><span style="color:#E1E4E8;">                                       </span><span style="color:#FFAB70;">transform</span><span style="color:#F97583;">=</span><span style="color:#79B8FF;">None</span><span style="color:#E1E4E8;">,</span></span>
<span class="line"><span style="color:#E1E4E8;">                                       </span><span style="color:#FFAB70;">target_transform</span><span style="color:#F97583;">=</span><span style="color:#79B8FF;">None</span><span style="color:#E1E4E8;">,</span></span>
<span class="line"><span style="color:#E1E4E8;">                                       </span><span style="color:#FFAB70;">download</span><span style="color:#F97583;">=</span><span style="color:#79B8FF;">True</span><span style="color:#E1E4E8;">)</span></span></code></pre><pre class="shiki github-light vp-code-light"><code><span class="line"><span style="color:#6A737D;"># 以MNIST为例</span></span>
<span class="line"><span style="color:#D73A49;">import</span><span style="color:#24292E;"> torchvision</span></span>
<span class="line"><span style="color:#24292E;">mnist_dataset </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> torchvision.datasets.MNIST(</span><span style="color:#E36209;">root</span><span style="color:#D73A49;">=</span><span style="color:#032F62;">&#39;./data&#39;</span><span style="color:#24292E;">,</span></span>
<span class="line"><span style="color:#24292E;">                                       </span><span style="color:#E36209;">train</span><span style="color:#D73A49;">=</span><span style="color:#005CC5;">True</span><span style="color:#24292E;">,</span></span>
<span class="line"><span style="color:#24292E;">                                       </span><span style="color:#E36209;">transform</span><span style="color:#D73A49;">=</span><span style="color:#005CC5;">None</span><span style="color:#24292E;">,</span></span>
<span class="line"><span style="color:#24292E;">                                       </span><span style="color:#E36209;">target_transform</span><span style="color:#D73A49;">=</span><span style="color:#005CC5;">None</span><span style="color:#24292E;">,</span></span>
<span class="line"><span style="color:#24292E;">                                       </span><span style="color:#E36209;">download</span><span style="color:#D73A49;">=</span><span style="color:#005CC5;">True</span><span style="color:#24292E;">)</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br></div></div><p>torchvision.datasets.MNIST 是一个类，对它进行实例化，即可返回一个 MNIST 数据集对象。构造函数包括包含 5 个参数：</p><ul><li>root：是一个字符串，用于指定你想要保存 MNIST 数据集的位置。如果 download 是 Flase，则会从目标位置读取数据集；</li><li>download：布尔类型，表示是否下载数据集。如果为 True，则会自动从网上下载这个数据集，存储到 root 指定的位置。如果指定位置已经存在数据集文件，则不会重复下载；</li><li>train：布尔类型，表示是否加载训练集数据。如果为 True，则只加载训练数据。如果为 False，则只加载测试数据集。这里需要注意，并不是所有的数据集都做了训练集和测试集的划分，这个参数并不一定是有效参数，具体需要参考官方接口说明文档；</li><li>transform：用于对图像进行预处理操作，例如数据增强、归一化、旋转或缩放等。这些操作我们会在下节课展开讲解；</li><li>target_transform：用于对图像标签进行预处理操作。</li></ul><p>运行上述的代码后，程序会首先去指定的网址下载了 MNIST 数据集，然后进行了解压缩等操作。如果你再次运行相同的代码，则不会再有下载的过程。</p><p>如果你用 type 函数查看一下 mnist_dataset 的类型，就可以得到 torchvision.datasets.mnist.MNIST ，而这个类是之前我们介绍过的 Dataset 类的派生类。相当于 torchvision.datasets ，它已经帮我们写好了对 Dataset 类的继承，完成了对数据集的封装，我们直接使用即可。</p><p>这里我们主要以 MNIST 为例，进行了说明。其它的数据集使用方法类似，调用的时候你只要需要将类名 “MNIST” 换成其它数据集名字即可。</p><h1 id="数据预览" tabindex="-1">数据预览 <a class="header-anchor" href="#数据预览" aria-label="Permalink to &quot;数据预览&quot;">​</a></h1><p>完成了数据读取工作，我们得到的是对应的 mnist_dataset，刚才已经讲过了，这是一个封装了的数据集。</p><p>如果想要查看 mnist_dataset 中的具体内容，我们需要把它转化为列表。（如果 IOPub data rate 超限，可以只加载测试集数据，令 train=False）</p><div class="language-python vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki github-dark vp-code-dark"><code><span class="line"><span style="color:#E1E4E8;">mnist_dataset_list </span><span style="color:#F97583;">=</span><span style="color:#E1E4E8;"> </span><span style="color:#79B8FF;">list</span><span style="color:#E1E4E8;">(mnist_dataset)</span></span>
<span class="line"><span style="color:#79B8FF;">print</span><span style="color:#E1E4E8;">(mnist_dataset_list)</span></span></code></pre><pre class="shiki github-light vp-code-light"><code><span class="line"><span style="color:#24292E;">mnist_dataset_list </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">list</span><span style="color:#24292E;">(mnist_dataset)</span></span>
<span class="line"><span style="color:#005CC5;">print</span><span style="color:#24292E;">(mnist_dataset_list)</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br></div></div><p>转换后的数据集对象变成了一个元组列表，每个元组有两个元素，第一个元素是图像数据，第二个元素是图像的标签。</p><p>这里图像数据是 PIL.Image.Image 类型的，这种类型可以直接在 Jupyter 中显示出来。显示一条数据的代码如下。</p><div class="language-python vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki github-dark vp-code-dark"><code><span class="line"><span style="color:#E1E4E8;">display(mnist_dataset_list[</span><span style="color:#79B8FF;">0</span><span style="color:#E1E4E8;">][</span><span style="color:#79B8FF;">0</span><span style="color:#E1E4E8;">])</span></span>
<span class="line"><span style="color:#79B8FF;">print</span><span style="color:#E1E4E8;">(</span><span style="color:#9ECBFF;">&quot;Image label is:&quot;</span><span style="color:#E1E4E8;">, mnist_dataset_list[</span><span style="color:#79B8FF;">0</span><span style="color:#E1E4E8;">][</span><span style="color:#79B8FF;">1</span><span style="color:#E1E4E8;">])</span></span></code></pre><pre class="shiki github-light vp-code-light"><code><span class="line"><span style="color:#24292E;">display(mnist_dataset_list[</span><span style="color:#005CC5;">0</span><span style="color:#24292E;">][</span><span style="color:#005CC5;">0</span><span style="color:#24292E;">])</span></span>
<span class="line"><span style="color:#005CC5;">print</span><span style="color:#24292E;">(</span><span style="color:#032F62;">&quot;Image label is:&quot;</span><span style="color:#24292E;">, mnist_dataset_list[</span><span style="color:#005CC5;">0</span><span style="color:#24292E;">][</span><span style="color:#005CC5;">1</span><span style="color:#24292E;">])</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br></div></div><p>上面介绍了两种读取数据的方法，也就是自定义和读取常用图像数据集。最通用的数据读取方法，就是自己定义一个 Dataset 的派生类。而读取常用的图像数据集，就可以利用 PyTorch 提供的视觉包 Torchvision。</p><p>极客时间版权所有: <a href="https://time.geekbang.org/column/article/429826" target="_blank" rel="noreferrer">https://time.geekbang.org/column/article/429826</a></p><p>(有删改)</p>`,54),o=[e];function t(r,c,i,y,E,d){return a(),n("div",null,o)}const m=s(p,[["render",t]]);export{F as __pageData,m as default};
