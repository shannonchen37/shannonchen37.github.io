import{_ as a,o as t,c as e,U as r}from"./chunks/framework.489e5108.js";const x=JSON.parse('{"title":"SimCLR","description":"","frontmatter":{},"headers":[],"relativePath":"4.人工智能/4.6.8.5SimCLR.md","filePath":"4.人工智能/4.6.8.5SimCLR.md","lastUpdated":1696176798000}'),i={name:"4.人工智能/4.6.8.5SimCLR.md"},o=r('<h1 id="simclr" tabindex="-1">SimCLR <a class="header-anchor" href="#simclr" aria-label="Permalink to &quot;SimCLR&quot;">​</a></h1><p>顾名思义，以‘SIMPLE’为主，这个模型主打的就是简单。</p><h1 id="模型结构" tabindex="-1">模型结构 <a class="header-anchor" href="#模型结构" aria-label="Permalink to &quot;模型结构&quot;">​</a></h1><p>x 是输入的图片，它经过两种不同的数据增强得到 xi 和 xj 两个正样本，而同一个 mini-batch 里的所有其他样本都作为负样本。<del>说白了还是个体判别任务</del></p><p><img src="https://cdn.xyxsw.site/boxcnq5TYzSltn6CsPM3Bn3xxAb.png" alt=""></p><p>左右的<strong> f 都是编码器</strong>，并且是<strong>完全一致共享权重</strong>的，可以说是同一个。</p><p>而 g 是一层 mlp 结构，只在训练中使用，<strong>应用到下游任务时用的仅仅是 f</strong>（与前面几篇一样都是 RES50），很神奇的是，就仅仅多了这么一层 mlp，它在 imagenet 上的正确率直接加了十个点。</p><p>关于这点也很奇怪，作者做了很多实验但是也没有很合理的解释。</p><p>最后的对比学习是对 zi 和 zj 做的。</p><p>下面这个是更加具体的流程图</p><p><img src="https://cdn.xyxsw.site/boxcnj3FZsRiJbWsKW07b9B8Fkb.png" alt=""></p><h1 id="总结" tabindex="-1">总结 <a class="header-anchor" href="#总结" aria-label="Permalink to &quot;总结&quot;">​</a></h1><p>因为这个真的很简单，没有太多可讲的，它就是单纯的简单且效果拔群，想具体了解数据增强相关或者具体效果对比的可以去看一下<a href="https://arxiv.org/pdf/2002.05709v3" target="_blank" rel="noreferrer">原论文</a>。</p><h1 id="另外" tabindex="-1">另外 <a class="header-anchor" href="#另外" aria-label="Permalink to &quot;另外&quot;">​</a></h1><p>SimCLR 也有 v2，缝合了 MoCo 的方法，同样不展开了。</p>',15),s=[o];function n(p,l,c,d,_,h){return t(),e("div",null,s)}const f=a(i,[["render",n]]);export{x as __pageData,f as default};
