import{_ as a,I as l,o as p,c as o,x as e,U as s}from"./chunks/framework.489e5108.js";const d=JSON.parse('{"title":"ResNet","description":"","frontmatter":{},"headers":[],"relativePath":"4.人工智能/4.6.5.3.3ResNet.md","filePath":"4.人工智能/4.6.5.3.3ResNet.md","lastUpdated":1696176798000}'),c={name:"4.人工智能/4.6.5.3.3ResNet.md"},r=s(`<h1 id="resnet" tabindex="-1">ResNet <a class="header-anchor" href="#resnet" aria-label="Permalink to &quot;ResNet&quot;">​</a></h1><div class="warning custom-block"><p class="custom-block-title">🕶</p><p>残差神经网络 (ResNet) 是由微软研究院的何恺明大神团队提出的一个经典网络模型，一经现世就成为了沿用至今的超级 Backbone。</p></div><p><a href="https://zhuanlan.zhihu.com/p/101332297" target="_blank" rel="noreferrer">知乎</a></p><p><a href="https://arxiv.org/pdf/1512.03385.pdf" target="_blank" rel="noreferrer">论文</a></p><h2 id="why-residual" tabindex="-1">WHY residual? <a class="header-anchor" href="#why-residual" aria-label="Permalink to &quot;WHY residual?&quot;">​</a></h2><div class="warning custom-block"><p class="custom-block-title">🎨</p><p>在 ResNet 提出之前，所有的神经网络都是通过卷积层和池化层的叠加组成的。 人们认为卷积层和池化层的层数越多，获取到的图片特征信息越全，学习效果也就越好。但是在实际的试验中发现，随着卷积层和池化层的叠加，不但没有出现学习效果越来越好的情况，反而出现两种问题：</p><ul><li>梯度消失和梯度爆炸</li></ul><p>梯度消失：若每一层的梯度误差小于 1，反向传播时，网络越深，梯度越趋近于 0</p><p>梯度爆炸：若每一层的梯度误差大于 1，反向传播时，网络越深，梯度越趋近于无穷大</p><ul><li>退化现象</li></ul><p>如图所示，随着层数越来越深，预测的效果反而越来越差 (error 越大)</p></div><p><img src="https://cdn.xyxsw.site/boxcnBDfBnOPmS0btwNseKvsN6f.png" alt=""></p><h2 id="网络模型" tabindex="-1">网络模型 <a class="header-anchor" href="#网络模型" aria-label="Permalink to &quot;网络模型&quot;">​</a></h2><p><img src="https://cdn.xyxsw.site/boxcnn8a16DYyEPEVuHxvvw7eAf.png" alt=""></p><div class="warning custom-block"><p class="custom-block-title">😺</p><p>我们可以看到，ResNet 的网络依旧非常深，这是因为研究团队不仅发现了退化现象，还采用出一个可以将网络继续加深的 trick：shortcut，亦即我们所说的 residual。</p><ul><li>为了解决梯度消失或梯度爆炸问题，ResNet 论文提出通过数据的预处理以及在网络中使用 BN（Batch Normalization）层来解决。</li><li>为了解决深层网络中的退化问题，可以人为地让神经网络某些层跳过下一层神经元的连接，隔层相连，弱化每层之间的强联系。这种神经网络被称为 残差网络 (ResNets)。ResNet 论文提出了 residual 结构（残差结构）来减轻退化问题。</li></ul></div><h3 id="residual-结构" tabindex="-1">residual 结构 <a class="header-anchor" href="#residual-结构" aria-label="Permalink to &quot;residual 结构&quot;">​</a></h3><p><img src="https://cdn.xyxsw.site/boxcnhgVaLChu3O2omGJKzFU7uB.png" alt=""></p><h2 id="网络代码" tabindex="-1">网络代码 <a class="header-anchor" href="#网络代码" aria-label="Permalink to &quot;网络代码&quot;">​</a></h2><div class="language-python vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki github-dark vp-code-dark"><code><span class="line"><span style="color:#F97583;">import</span><span style="color:#E1E4E8;"> torch.nn </span><span style="color:#F97583;">as</span><span style="color:#E1E4E8;"> nn</span></span>
<span class="line"><span style="color:#F97583;">import</span><span style="color:#E1E4E8;"> torch</span></span>
<span class="line"></span>
<span class="line"></span>
<span class="line"><span style="color:#6A737D;"># ResNet18/34的残差结构，用的是2个3x3的卷积</span></span>
<span class="line"><span style="color:#F97583;">class</span><span style="color:#E1E4E8;"> </span><span style="color:#B392F0;">BasicBlock</span><span style="color:#E1E4E8;">(</span><span style="color:#B392F0;">nn</span><span style="color:#E1E4E8;">.</span><span style="color:#B392F0;">Module</span><span style="color:#E1E4E8;">):</span></span>
<span class="line"><span style="color:#E1E4E8;">    expansion </span><span style="color:#F97583;">=</span><span style="color:#E1E4E8;"> </span><span style="color:#79B8FF;">1</span><span style="color:#E1E4E8;">  </span><span style="color:#6A737D;"># 残差结构中，主分支的卷积核个数是否发生变化，不变则为1</span></span>
<span class="line"></span>
<span class="line"><span style="color:#E1E4E8;">    </span><span style="color:#F97583;">def</span><span style="color:#E1E4E8;"> </span><span style="color:#79B8FF;">__init__</span><span style="color:#E1E4E8;">(self, in_channel, out_channel, stride</span><span style="color:#F97583;">=</span><span style="color:#79B8FF;">1</span><span style="color:#E1E4E8;">, downsample</span><span style="color:#F97583;">=</span><span style="color:#79B8FF;">None</span><span style="color:#E1E4E8;">):  </span><span style="color:#6A737D;"># downsample对应虚线残差结构</span></span>
<span class="line"><span style="color:#E1E4E8;">        </span><span style="color:#79B8FF;">super</span><span style="color:#E1E4E8;">(BasicBlock, </span><span style="color:#79B8FF;">self</span><span style="color:#E1E4E8;">).</span><span style="color:#79B8FF;">__init__</span><span style="color:#E1E4E8;">()</span></span>
<span class="line"><span style="color:#E1E4E8;">        </span><span style="color:#79B8FF;">self</span><span style="color:#E1E4E8;">.conv1 </span><span style="color:#F97583;">=</span><span style="color:#E1E4E8;"> nn.Conv2d(</span><span style="color:#FFAB70;">in_channels</span><span style="color:#F97583;">=</span><span style="color:#E1E4E8;">in_channel, </span><span style="color:#FFAB70;">out_channels</span><span style="color:#F97583;">=</span><span style="color:#E1E4E8;">out_channel,</span></span>
<span class="line"><span style="color:#E1E4E8;">                               </span><span style="color:#FFAB70;">kernel_size</span><span style="color:#F97583;">=</span><span style="color:#79B8FF;">3</span><span style="color:#E1E4E8;">, </span><span style="color:#FFAB70;">stride</span><span style="color:#F97583;">=</span><span style="color:#E1E4E8;">stride, </span><span style="color:#FFAB70;">padding</span><span style="color:#F97583;">=</span><span style="color:#79B8FF;">1</span><span style="color:#E1E4E8;">, </span><span style="color:#FFAB70;">bias</span><span style="color:#F97583;">=</span><span style="color:#79B8FF;">False</span><span style="color:#E1E4E8;">)</span></span>
<span class="line"><span style="color:#E1E4E8;">        </span><span style="color:#79B8FF;">self</span><span style="color:#E1E4E8;">.bn1 </span><span style="color:#F97583;">=</span><span style="color:#E1E4E8;"> nn.BatchNorm2d(out_channel)</span></span>
<span class="line"><span style="color:#E1E4E8;">        </span><span style="color:#79B8FF;">self</span><span style="color:#E1E4E8;">.relu </span><span style="color:#F97583;">=</span><span style="color:#E1E4E8;"> nn.ReLU()</span></span>
<span class="line"><span style="color:#E1E4E8;">        </span><span style="color:#79B8FF;">self</span><span style="color:#E1E4E8;">.conv2 </span><span style="color:#F97583;">=</span><span style="color:#E1E4E8;"> nn.Conv2d(</span><span style="color:#FFAB70;">in_channels</span><span style="color:#F97583;">=</span><span style="color:#E1E4E8;">out_channel, </span><span style="color:#FFAB70;">out_channels</span><span style="color:#F97583;">=</span><span style="color:#E1E4E8;">out_channel,</span></span>
<span class="line"><span style="color:#E1E4E8;">                               </span><span style="color:#FFAB70;">kernel_size</span><span style="color:#F97583;">=</span><span style="color:#79B8FF;">3</span><span style="color:#E1E4E8;">, </span><span style="color:#FFAB70;">stride</span><span style="color:#F97583;">=</span><span style="color:#79B8FF;">1</span><span style="color:#E1E4E8;">, </span><span style="color:#FFAB70;">padding</span><span style="color:#F97583;">=</span><span style="color:#79B8FF;">1</span><span style="color:#E1E4E8;">, </span><span style="color:#FFAB70;">bias</span><span style="color:#F97583;">=</span><span style="color:#79B8FF;">False</span><span style="color:#E1E4E8;">)</span></span>
<span class="line"><span style="color:#E1E4E8;">        </span><span style="color:#79B8FF;">self</span><span style="color:#E1E4E8;">.bn2 </span><span style="color:#F97583;">=</span><span style="color:#E1E4E8;"> nn.BatchNorm2d(out_channel)</span></span>
<span class="line"><span style="color:#E1E4E8;">        </span><span style="color:#79B8FF;">self</span><span style="color:#E1E4E8;">.downsample </span><span style="color:#F97583;">=</span><span style="color:#E1E4E8;"> downsample</span></span>
<span class="line"></span>
<span class="line"><span style="color:#E1E4E8;">    </span><span style="color:#F97583;">def</span><span style="color:#E1E4E8;"> </span><span style="color:#B392F0;">forward</span><span style="color:#E1E4E8;">(self, x):</span></span>
<span class="line"><span style="color:#E1E4E8;">        identity </span><span style="color:#F97583;">=</span><span style="color:#E1E4E8;"> x</span></span>
<span class="line"><span style="color:#E1E4E8;">        </span><span style="color:#F97583;">if</span><span style="color:#E1E4E8;"> </span><span style="color:#79B8FF;">self</span><span style="color:#E1E4E8;">.downsample </span><span style="color:#F97583;">is</span><span style="color:#E1E4E8;"> </span><span style="color:#F97583;">not</span><span style="color:#E1E4E8;"> </span><span style="color:#79B8FF;">None</span><span style="color:#E1E4E8;">:  </span><span style="color:#6A737D;"># 虚线残差结构，需要下采样</span></span>
<span class="line"><span style="color:#E1E4E8;">            identity </span><span style="color:#F97583;">=</span><span style="color:#E1E4E8;"> </span><span style="color:#79B8FF;">self</span><span style="color:#E1E4E8;">.downsample(x)  </span><span style="color:#6A737D;"># 捷径分支 short cut</span></span>
<span class="line"></span>
<span class="line"><span style="color:#E1E4E8;">        out </span><span style="color:#F97583;">=</span><span style="color:#E1E4E8;"> </span><span style="color:#79B8FF;">self</span><span style="color:#E1E4E8;">.conv1(x)</span></span>
<span class="line"><span style="color:#E1E4E8;">        out </span><span style="color:#F97583;">=</span><span style="color:#E1E4E8;"> </span><span style="color:#79B8FF;">self</span><span style="color:#E1E4E8;">.bn1(out)</span></span>
<span class="line"><span style="color:#E1E4E8;">        out </span><span style="color:#F97583;">=</span><span style="color:#E1E4E8;"> </span><span style="color:#79B8FF;">self</span><span style="color:#E1E4E8;">.relu(out)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#E1E4E8;">        out </span><span style="color:#F97583;">=</span><span style="color:#E1E4E8;"> </span><span style="color:#79B8FF;">self</span><span style="color:#E1E4E8;">.conv2(out)</span></span>
<span class="line"><span style="color:#E1E4E8;">        out </span><span style="color:#F97583;">=</span><span style="color:#E1E4E8;"> </span><span style="color:#79B8FF;">self</span><span style="color:#E1E4E8;">.bn2(out)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#E1E4E8;">        out </span><span style="color:#F97583;">+=</span><span style="color:#E1E4E8;"> identity</span></span>
<span class="line"><span style="color:#E1E4E8;">        out </span><span style="color:#F97583;">=</span><span style="color:#E1E4E8;"> </span><span style="color:#79B8FF;">self</span><span style="color:#E1E4E8;">.relu(out)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#E1E4E8;">        </span><span style="color:#F97583;">return</span><span style="color:#E1E4E8;"> out</span></span>
<span class="line"></span>
<span class="line"><span style="color:#6A737D;"># ResNet50/101/152的残差结构，用的是1x1+3x3+1x1的卷积</span></span>
<span class="line"><span style="color:#F97583;">class</span><span style="color:#E1E4E8;"> </span><span style="color:#B392F0;">Bottleneck</span><span style="color:#E1E4E8;">(</span><span style="color:#B392F0;">nn</span><span style="color:#E1E4E8;">.</span><span style="color:#B392F0;">Module</span><span style="color:#E1E4E8;">):</span></span>
<span class="line"><span style="color:#E1E4E8;">    expansion </span><span style="color:#F97583;">=</span><span style="color:#E1E4E8;"> </span><span style="color:#79B8FF;">4</span><span style="color:#E1E4E8;">  </span><span style="color:#6A737D;"># 残差结构中第三层卷积核个数是第一/二层卷积核个数的4倍</span></span>
<span class="line"></span>
<span class="line"><span style="color:#E1E4E8;">    </span><span style="color:#F97583;">def</span><span style="color:#E1E4E8;"> </span><span style="color:#79B8FF;">__init__</span><span style="color:#E1E4E8;">(self, in_channel, out_channel, stride</span><span style="color:#F97583;">=</span><span style="color:#79B8FF;">1</span><span style="color:#E1E4E8;">, downsample</span><span style="color:#F97583;">=</span><span style="color:#79B8FF;">None</span><span style="color:#E1E4E8;">):</span></span>
<span class="line"><span style="color:#E1E4E8;">        </span><span style="color:#79B8FF;">super</span><span style="color:#E1E4E8;">(Bottleneck, </span><span style="color:#79B8FF;">self</span><span style="color:#E1E4E8;">).</span><span style="color:#79B8FF;">__init__</span><span style="color:#E1E4E8;">()</span></span>
<span class="line"><span style="color:#E1E4E8;">        </span><span style="color:#79B8FF;">self</span><span style="color:#E1E4E8;">.conv1 </span><span style="color:#F97583;">=</span><span style="color:#E1E4E8;"> nn.Conv2d(</span><span style="color:#FFAB70;">in_channels</span><span style="color:#F97583;">=</span><span style="color:#E1E4E8;">in_channel, </span><span style="color:#FFAB70;">out_channels</span><span style="color:#F97583;">=</span><span style="color:#E1E4E8;">out_channel,</span></span>
<span class="line"><span style="color:#E1E4E8;">                               </span><span style="color:#FFAB70;">kernel_size</span><span style="color:#F97583;">=</span><span style="color:#79B8FF;">1</span><span style="color:#E1E4E8;">, </span><span style="color:#FFAB70;">stride</span><span style="color:#F97583;">=</span><span style="color:#79B8FF;">1</span><span style="color:#E1E4E8;">, </span><span style="color:#FFAB70;">bias</span><span style="color:#F97583;">=</span><span style="color:#79B8FF;">False</span><span style="color:#E1E4E8;">)  </span><span style="color:#6A737D;"># squeeze channels</span></span>
<span class="line"><span style="color:#E1E4E8;">        </span><span style="color:#79B8FF;">self</span><span style="color:#E1E4E8;">.bn1 </span><span style="color:#F97583;">=</span><span style="color:#E1E4E8;"> nn.BatchNorm2d(out_channel)</span></span>
<span class="line"><span style="color:#E1E4E8;">        </span><span style="color:#6A737D;"># -----------------------------------------</span></span>
<span class="line"><span style="color:#E1E4E8;">        </span><span style="color:#79B8FF;">self</span><span style="color:#E1E4E8;">.conv2 </span><span style="color:#F97583;">=</span><span style="color:#E1E4E8;"> nn.Conv2d(</span><span style="color:#FFAB70;">in_channels</span><span style="color:#F97583;">=</span><span style="color:#E1E4E8;">out_channel, </span><span style="color:#FFAB70;">out_channels</span><span style="color:#F97583;">=</span><span style="color:#E1E4E8;">out_channel,</span></span>
<span class="line"><span style="color:#E1E4E8;">                               </span><span style="color:#FFAB70;">kernel_size</span><span style="color:#F97583;">=</span><span style="color:#79B8FF;">3</span><span style="color:#E1E4E8;">, </span><span style="color:#FFAB70;">stride</span><span style="color:#F97583;">=</span><span style="color:#E1E4E8;">stride, </span><span style="color:#FFAB70;">bias</span><span style="color:#F97583;">=</span><span style="color:#79B8FF;">False</span><span style="color:#E1E4E8;">, </span><span style="color:#FFAB70;">padding</span><span style="color:#F97583;">=</span><span style="color:#79B8FF;">1</span><span style="color:#E1E4E8;">)</span></span>
<span class="line"><span style="color:#E1E4E8;">        </span><span style="color:#79B8FF;">self</span><span style="color:#E1E4E8;">.bn2 </span><span style="color:#F97583;">=</span><span style="color:#E1E4E8;"> nn.BatchNorm2d(out_channel)</span></span>
<span class="line"><span style="color:#E1E4E8;">        </span><span style="color:#6A737D;"># -----------------------------------------</span></span>
<span class="line"><span style="color:#E1E4E8;">        </span><span style="color:#79B8FF;">self</span><span style="color:#E1E4E8;">.conv3 </span><span style="color:#F97583;">=</span><span style="color:#E1E4E8;"> nn.Conv2d(</span><span style="color:#FFAB70;">in_channels</span><span style="color:#F97583;">=</span><span style="color:#E1E4E8;">out_channel, </span><span style="color:#FFAB70;">out_channels</span><span style="color:#F97583;">=</span><span style="color:#E1E4E8;">out_channel </span><span style="color:#F97583;">*</span><span style="color:#E1E4E8;"> </span><span style="color:#79B8FF;">self</span><span style="color:#E1E4E8;">.expansion,</span></span>
<span class="line"><span style="color:#E1E4E8;">                               </span><span style="color:#FFAB70;">kernel_size</span><span style="color:#F97583;">=</span><span style="color:#79B8FF;">1</span><span style="color:#E1E4E8;">, </span><span style="color:#FFAB70;">stride</span><span style="color:#F97583;">=</span><span style="color:#79B8FF;">1</span><span style="color:#E1E4E8;">, </span><span style="color:#FFAB70;">bias</span><span style="color:#F97583;">=</span><span style="color:#79B8FF;">False</span><span style="color:#E1E4E8;">)  </span><span style="color:#6A737D;"># unsqueeze channels</span></span>
<span class="line"><span style="color:#E1E4E8;">        </span><span style="color:#79B8FF;">self</span><span style="color:#E1E4E8;">.bn3 </span><span style="color:#F97583;">=</span><span style="color:#E1E4E8;"> nn.BatchNorm2d(out_channel </span><span style="color:#F97583;">*</span><span style="color:#E1E4E8;"> </span><span style="color:#79B8FF;">self</span><span style="color:#E1E4E8;">.expansion)</span></span>
<span class="line"><span style="color:#E1E4E8;">        </span><span style="color:#79B8FF;">self</span><span style="color:#E1E4E8;">.relu </span><span style="color:#F97583;">=</span><span style="color:#E1E4E8;"> nn.ReLU(</span><span style="color:#FFAB70;">inplace</span><span style="color:#F97583;">=</span><span style="color:#79B8FF;">True</span><span style="color:#E1E4E8;">)</span></span>
<span class="line"><span style="color:#E1E4E8;">        </span><span style="color:#79B8FF;">self</span><span style="color:#E1E4E8;">.downsample </span><span style="color:#F97583;">=</span><span style="color:#E1E4E8;"> downsample</span></span>
<span class="line"></span>
<span class="line"><span style="color:#E1E4E8;">    </span><span style="color:#F97583;">def</span><span style="color:#E1E4E8;"> </span><span style="color:#B392F0;">forward</span><span style="color:#E1E4E8;">(self, x):</span></span>
<span class="line"><span style="color:#E1E4E8;">        identity </span><span style="color:#F97583;">=</span><span style="color:#E1E4E8;"> x</span></span>
<span class="line"><span style="color:#E1E4E8;">        </span><span style="color:#F97583;">if</span><span style="color:#E1E4E8;"> </span><span style="color:#79B8FF;">self</span><span style="color:#E1E4E8;">.downsample </span><span style="color:#F97583;">is</span><span style="color:#E1E4E8;"> </span><span style="color:#F97583;">not</span><span style="color:#E1E4E8;"> </span><span style="color:#79B8FF;">None</span><span style="color:#E1E4E8;">:</span></span>
<span class="line"><span style="color:#E1E4E8;">            identity </span><span style="color:#F97583;">=</span><span style="color:#E1E4E8;"> </span><span style="color:#79B8FF;">self</span><span style="color:#E1E4E8;">.downsample(x)  </span><span style="color:#6A737D;"># 捷径分支 short cut</span></span>
<span class="line"></span>
<span class="line"><span style="color:#E1E4E8;">        out </span><span style="color:#F97583;">=</span><span style="color:#E1E4E8;"> </span><span style="color:#79B8FF;">self</span><span style="color:#E1E4E8;">.conv1(x)</span></span>
<span class="line"><span style="color:#E1E4E8;">        out </span><span style="color:#F97583;">=</span><span style="color:#E1E4E8;"> </span><span style="color:#79B8FF;">self</span><span style="color:#E1E4E8;">.bn1(out)</span></span>
<span class="line"><span style="color:#E1E4E8;">        out </span><span style="color:#F97583;">=</span><span style="color:#E1E4E8;"> </span><span style="color:#79B8FF;">self</span><span style="color:#E1E4E8;">.relu(out)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#E1E4E8;">        out </span><span style="color:#F97583;">=</span><span style="color:#E1E4E8;"> </span><span style="color:#79B8FF;">self</span><span style="color:#E1E4E8;">.conv2(out)</span></span>
<span class="line"><span style="color:#E1E4E8;">        out </span><span style="color:#F97583;">=</span><span style="color:#E1E4E8;"> </span><span style="color:#79B8FF;">self</span><span style="color:#E1E4E8;">.bn2(out)</span></span>
<span class="line"><span style="color:#E1E4E8;">        out </span><span style="color:#F97583;">=</span><span style="color:#E1E4E8;"> </span><span style="color:#79B8FF;">self</span><span style="color:#E1E4E8;">.relu(out)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#E1E4E8;">        out </span><span style="color:#F97583;">=</span><span style="color:#E1E4E8;"> </span><span style="color:#79B8FF;">self</span><span style="color:#E1E4E8;">.conv3(out)</span></span>
<span class="line"><span style="color:#E1E4E8;">        out </span><span style="color:#F97583;">=</span><span style="color:#E1E4E8;"> </span><span style="color:#79B8FF;">self</span><span style="color:#E1E4E8;">.bn3(out)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#E1E4E8;">        out </span><span style="color:#F97583;">+=</span><span style="color:#E1E4E8;"> identity</span></span>
<span class="line"><span style="color:#E1E4E8;">        out </span><span style="color:#F97583;">=</span><span style="color:#E1E4E8;"> </span><span style="color:#79B8FF;">self</span><span style="color:#E1E4E8;">.relu(out)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#E1E4E8;">        </span><span style="color:#F97583;">return</span><span style="color:#E1E4E8;"> out</span></span>
<span class="line"></span>
<span class="line"></span>
<span class="line"><span style="color:#F97583;">class</span><span style="color:#E1E4E8;"> </span><span style="color:#B392F0;">ResNet</span><span style="color:#E1E4E8;">(</span><span style="color:#B392F0;">nn</span><span style="color:#E1E4E8;">.</span><span style="color:#B392F0;">Module</span><span style="color:#E1E4E8;">):</span></span>
<span class="line"><span style="color:#E1E4E8;">    </span><span style="color:#6A737D;"># block = BasicBlock or Bottleneck</span></span>
<span class="line"><span style="color:#E1E4E8;">    </span><span style="color:#6A737D;"># block_num为残差结构中conv2_x~conv5_x中残差块个数，是一个列表</span></span>
<span class="line"><span style="color:#E1E4E8;">    </span><span style="color:#F97583;">def</span><span style="color:#E1E4E8;"> </span><span style="color:#79B8FF;">__init__</span><span style="color:#E1E4E8;">(self, block, blocks_num, num_classes</span><span style="color:#F97583;">=</span><span style="color:#79B8FF;">1000</span><span style="color:#E1E4E8;">, include_top</span><span style="color:#F97583;">=</span><span style="color:#79B8FF;">True</span><span style="color:#E1E4E8;">):</span></span>
<span class="line"><span style="color:#E1E4E8;">        </span><span style="color:#79B8FF;">super</span><span style="color:#E1E4E8;">(ResNet, </span><span style="color:#79B8FF;">self</span><span style="color:#E1E4E8;">).</span><span style="color:#79B8FF;">__init__</span><span style="color:#E1E4E8;">()</span></span>
<span class="line"><span style="color:#E1E4E8;">        </span><span style="color:#79B8FF;">self</span><span style="color:#E1E4E8;">.include_top </span><span style="color:#F97583;">=</span><span style="color:#E1E4E8;"> include_top</span></span>
<span class="line"><span style="color:#E1E4E8;">        </span><span style="color:#79B8FF;">self</span><span style="color:#E1E4E8;">.in_channel </span><span style="color:#F97583;">=</span><span style="color:#E1E4E8;"> </span><span style="color:#79B8FF;">64</span></span>
<span class="line"></span>
<span class="line"><span style="color:#E1E4E8;">        </span><span style="color:#79B8FF;">self</span><span style="color:#E1E4E8;">.conv1 </span><span style="color:#F97583;">=</span><span style="color:#E1E4E8;"> nn.Conv2d(</span><span style="color:#79B8FF;">3</span><span style="color:#E1E4E8;">, </span><span style="color:#79B8FF;">self</span><span style="color:#E1E4E8;">.in_channel, </span><span style="color:#FFAB70;">kernel_size</span><span style="color:#F97583;">=</span><span style="color:#79B8FF;">7</span><span style="color:#E1E4E8;">, </span><span style="color:#FFAB70;">stride</span><span style="color:#F97583;">=</span><span style="color:#79B8FF;">2</span><span style="color:#E1E4E8;">,</span></span>
<span class="line"><span style="color:#E1E4E8;">                               </span><span style="color:#FFAB70;">padding</span><span style="color:#F97583;">=</span><span style="color:#79B8FF;">3</span><span style="color:#E1E4E8;">, </span><span style="color:#FFAB70;">bias</span><span style="color:#F97583;">=</span><span style="color:#79B8FF;">False</span><span style="color:#E1E4E8;">)</span></span>
<span class="line"><span style="color:#E1E4E8;">        </span><span style="color:#79B8FF;">self</span><span style="color:#E1E4E8;">.bn1 </span><span style="color:#F97583;">=</span><span style="color:#E1E4E8;"> nn.BatchNorm2d(</span><span style="color:#79B8FF;">self</span><span style="color:#E1E4E8;">.in_channel)</span></span>
<span class="line"><span style="color:#E1E4E8;">        </span><span style="color:#79B8FF;">self</span><span style="color:#E1E4E8;">.relu </span><span style="color:#F97583;">=</span><span style="color:#E1E4E8;"> nn.ReLU(</span><span style="color:#FFAB70;">inplace</span><span style="color:#F97583;">=</span><span style="color:#79B8FF;">True</span><span style="color:#E1E4E8;">)</span></span>
<span class="line"><span style="color:#E1E4E8;">        </span><span style="color:#79B8FF;">self</span><span style="color:#E1E4E8;">.maxpool </span><span style="color:#F97583;">=</span><span style="color:#E1E4E8;"> nn.MaxPool2d(</span><span style="color:#FFAB70;">kernel_size</span><span style="color:#F97583;">=</span><span style="color:#79B8FF;">3</span><span style="color:#E1E4E8;">, </span><span style="color:#FFAB70;">stride</span><span style="color:#F97583;">=</span><span style="color:#79B8FF;">2</span><span style="color:#E1E4E8;">, </span><span style="color:#FFAB70;">padding</span><span style="color:#F97583;">=</span><span style="color:#79B8FF;">1</span><span style="color:#E1E4E8;">)</span></span>
<span class="line"><span style="color:#E1E4E8;">        </span><span style="color:#79B8FF;">self</span><span style="color:#E1E4E8;">.layer1 </span><span style="color:#F97583;">=</span><span style="color:#E1E4E8;"> </span><span style="color:#79B8FF;">self</span><span style="color:#E1E4E8;">._make_layer(block, </span><span style="color:#79B8FF;">64</span><span style="color:#E1E4E8;">, blocks_num[</span><span style="color:#79B8FF;">0</span><span style="color:#E1E4E8;">])             </span><span style="color:#6A737D;"># conv2_x</span></span>
<span class="line"><span style="color:#E1E4E8;">        </span><span style="color:#79B8FF;">self</span><span style="color:#E1E4E8;">.layer2 </span><span style="color:#F97583;">=</span><span style="color:#E1E4E8;"> </span><span style="color:#79B8FF;">self</span><span style="color:#E1E4E8;">._make_layer(block, </span><span style="color:#79B8FF;">128</span><span style="color:#E1E4E8;">, blocks_num[</span><span style="color:#79B8FF;">1</span><span style="color:#E1E4E8;">], </span><span style="color:#FFAB70;">stride</span><span style="color:#F97583;">=</span><span style="color:#79B8FF;">2</span><span style="color:#E1E4E8;">)  </span><span style="color:#6A737D;"># conv3_x</span></span>
<span class="line"><span style="color:#E1E4E8;">        </span><span style="color:#79B8FF;">self</span><span style="color:#E1E4E8;">.layer3 </span><span style="color:#F97583;">=</span><span style="color:#E1E4E8;"> </span><span style="color:#79B8FF;">self</span><span style="color:#E1E4E8;">._make_layer(block, </span><span style="color:#79B8FF;">256</span><span style="color:#E1E4E8;">, blocks_num[</span><span style="color:#79B8FF;">2</span><span style="color:#E1E4E8;">], </span><span style="color:#FFAB70;">stride</span><span style="color:#F97583;">=</span><span style="color:#79B8FF;">2</span><span style="color:#E1E4E8;">)  </span><span style="color:#6A737D;"># conv4_x</span></span>
<span class="line"><span style="color:#E1E4E8;">        </span><span style="color:#79B8FF;">self</span><span style="color:#E1E4E8;">.layer4 </span><span style="color:#F97583;">=</span><span style="color:#E1E4E8;"> </span><span style="color:#79B8FF;">self</span><span style="color:#E1E4E8;">._make_layer(block, </span><span style="color:#79B8FF;">512</span><span style="color:#E1E4E8;">, blocks_num[</span><span style="color:#79B8FF;">3</span><span style="color:#E1E4E8;">], </span><span style="color:#FFAB70;">stride</span><span style="color:#F97583;">=</span><span style="color:#79B8FF;">2</span><span style="color:#E1E4E8;">)  </span><span style="color:#6A737D;"># conv5_x</span></span>
<span class="line"><span style="color:#E1E4E8;">        </span><span style="color:#F97583;">if</span><span style="color:#E1E4E8;"> </span><span style="color:#79B8FF;">self</span><span style="color:#E1E4E8;">.include_top:</span></span>
<span class="line"><span style="color:#E1E4E8;">            </span><span style="color:#79B8FF;">self</span><span style="color:#E1E4E8;">.avgpool </span><span style="color:#F97583;">=</span><span style="color:#E1E4E8;"> nn.AdaptiveAvgPool2d((</span><span style="color:#79B8FF;">1</span><span style="color:#E1E4E8;">, </span><span style="color:#79B8FF;">1</span><span style="color:#E1E4E8;">))  </span><span style="color:#6A737D;"># output size = (1, 1)</span></span>
<span class="line"><span style="color:#E1E4E8;">            </span><span style="color:#79B8FF;">self</span><span style="color:#E1E4E8;">.fc </span><span style="color:#F97583;">=</span><span style="color:#E1E4E8;"> nn.Linear(</span><span style="color:#79B8FF;">512</span><span style="color:#E1E4E8;"> </span><span style="color:#F97583;">*</span><span style="color:#E1E4E8;"> block.expansion, num_classes)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#E1E4E8;">        </span><span style="color:#F97583;">for</span><span style="color:#E1E4E8;"> m </span><span style="color:#F97583;">in</span><span style="color:#E1E4E8;"> </span><span style="color:#79B8FF;">self</span><span style="color:#E1E4E8;">.modules():</span></span>
<span class="line"><span style="color:#E1E4E8;">            </span><span style="color:#F97583;">if</span><span style="color:#E1E4E8;"> </span><span style="color:#79B8FF;">isinstance</span><span style="color:#E1E4E8;">(m, nn.Conv2d):</span></span>
<span class="line"><span style="color:#E1E4E8;">                nn.init.kaiming_normal_(m.weight, </span><span style="color:#FFAB70;">mode</span><span style="color:#F97583;">=</span><span style="color:#9ECBFF;">&#39;fan_out&#39;</span><span style="color:#E1E4E8;">, </span><span style="color:#FFAB70;">nonlinearity</span><span style="color:#F97583;">=</span><span style="color:#9ECBFF;">&#39;relu&#39;</span><span style="color:#E1E4E8;">)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#E1E4E8;">    </span><span style="color:#6A737D;"># channel为残差结构中第一层卷积核个数</span></span>
<span class="line"><span style="color:#E1E4E8;">    </span><span style="color:#F97583;">def</span><span style="color:#E1E4E8;"> </span><span style="color:#B392F0;">_make_layer</span><span style="color:#E1E4E8;">(self, block, channel, block_num, stride</span><span style="color:#F97583;">=</span><span style="color:#79B8FF;">1</span><span style="color:#E1E4E8;">):</span></span>
<span class="line"><span style="color:#E1E4E8;">        downsample </span><span style="color:#F97583;">=</span><span style="color:#E1E4E8;"> </span><span style="color:#79B8FF;">None</span></span>
<span class="line"></span>
<span class="line"><span style="color:#E1E4E8;">        </span><span style="color:#6A737D;"># ResNet50/101/152的残差结构，block.expansion=4</span></span>
<span class="line"><span style="color:#E1E4E8;">        </span><span style="color:#F97583;">if</span><span style="color:#E1E4E8;"> stride </span><span style="color:#F97583;">!=</span><span style="color:#E1E4E8;"> </span><span style="color:#79B8FF;">1</span><span style="color:#E1E4E8;"> </span><span style="color:#F97583;">or</span><span style="color:#E1E4E8;"> </span><span style="color:#79B8FF;">self</span><span style="color:#E1E4E8;">.in_channel </span><span style="color:#F97583;">!=</span><span style="color:#E1E4E8;"> channel </span><span style="color:#F97583;">*</span><span style="color:#E1E4E8;"> block.expansion:</span></span>
<span class="line"><span style="color:#E1E4E8;">            downsample </span><span style="color:#F97583;">=</span><span style="color:#E1E4E8;"> nn.Sequential(</span></span>
<span class="line"><span style="color:#E1E4E8;">                nn.Conv2d(</span><span style="color:#79B8FF;">self</span><span style="color:#E1E4E8;">.in_channel, channel </span><span style="color:#F97583;">*</span><span style="color:#E1E4E8;"> block.expansion, </span><span style="color:#FFAB70;">kernel_size</span><span style="color:#F97583;">=</span><span style="color:#79B8FF;">1</span><span style="color:#E1E4E8;">, </span><span style="color:#FFAB70;">stride</span><span style="color:#F97583;">=</span><span style="color:#E1E4E8;">stride, </span><span style="color:#FFAB70;">bias</span><span style="color:#F97583;">=</span><span style="color:#79B8FF;">False</span><span style="color:#E1E4E8;">),</span></span>
<span class="line"><span style="color:#E1E4E8;">                nn.BatchNorm2d(channel </span><span style="color:#F97583;">*</span><span style="color:#E1E4E8;"> block.expansion))</span></span>
<span class="line"></span>
<span class="line"><span style="color:#E1E4E8;">        layers </span><span style="color:#F97583;">=</span><span style="color:#E1E4E8;"> []</span></span>
<span class="line"><span style="color:#E1E4E8;">        layers.append(block(</span><span style="color:#79B8FF;">self</span><span style="color:#E1E4E8;">.in_channel, channel, </span><span style="color:#FFAB70;">downsample</span><span style="color:#F97583;">=</span><span style="color:#E1E4E8;">downsample, </span><span style="color:#FFAB70;">stride</span><span style="color:#F97583;">=</span><span style="color:#E1E4E8;">stride))</span></span>
<span class="line"><span style="color:#E1E4E8;">        </span><span style="color:#79B8FF;">self</span><span style="color:#E1E4E8;">.in_channel </span><span style="color:#F97583;">=</span><span style="color:#E1E4E8;"> channel </span><span style="color:#F97583;">*</span><span style="color:#E1E4E8;"> block.expansion</span></span>
<span class="line"></span>
<span class="line"><span style="color:#E1E4E8;">        </span><span style="color:#F97583;">for</span><span style="color:#E1E4E8;"> _ </span><span style="color:#F97583;">in</span><span style="color:#E1E4E8;"> </span><span style="color:#79B8FF;">range</span><span style="color:#E1E4E8;">(</span><span style="color:#79B8FF;">1</span><span style="color:#E1E4E8;">, block_num):</span></span>
<span class="line"><span style="color:#E1E4E8;">            layers.append(block(</span><span style="color:#79B8FF;">self</span><span style="color:#E1E4E8;">.in_channel, channel))</span></span>
<span class="line"></span>
<span class="line"><span style="color:#E1E4E8;">        </span><span style="color:#F97583;">return</span><span style="color:#E1E4E8;"> nn.Sequential(</span><span style="color:#F97583;">*</span><span style="color:#E1E4E8;">layers)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#E1E4E8;">    </span><span style="color:#F97583;">def</span><span style="color:#E1E4E8;"> </span><span style="color:#B392F0;">forward</span><span style="color:#E1E4E8;">(self, x):</span></span>
<span class="line"><span style="color:#E1E4E8;">        x </span><span style="color:#F97583;">=</span><span style="color:#E1E4E8;"> </span><span style="color:#79B8FF;">self</span><span style="color:#E1E4E8;">.conv1(x)</span></span>
<span class="line"><span style="color:#E1E4E8;">        x </span><span style="color:#F97583;">=</span><span style="color:#E1E4E8;"> </span><span style="color:#79B8FF;">self</span><span style="color:#E1E4E8;">.bn1(x)</span></span>
<span class="line"><span style="color:#E1E4E8;">        x </span><span style="color:#F97583;">=</span><span style="color:#E1E4E8;"> </span><span style="color:#79B8FF;">self</span><span style="color:#E1E4E8;">.relu(x)</span></span>
<span class="line"><span style="color:#E1E4E8;">        x </span><span style="color:#F97583;">=</span><span style="color:#E1E4E8;"> </span><span style="color:#79B8FF;">self</span><span style="color:#E1E4E8;">.maxpool(x)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#E1E4E8;">        x </span><span style="color:#F97583;">=</span><span style="color:#E1E4E8;"> </span><span style="color:#79B8FF;">self</span><span style="color:#E1E4E8;">.layer1(x)</span></span>
<span class="line"><span style="color:#E1E4E8;">        x </span><span style="color:#F97583;">=</span><span style="color:#E1E4E8;"> </span><span style="color:#79B8FF;">self</span><span style="color:#E1E4E8;">.layer2(x)</span></span>
<span class="line"><span style="color:#E1E4E8;">        x </span><span style="color:#F97583;">=</span><span style="color:#E1E4E8;"> </span><span style="color:#79B8FF;">self</span><span style="color:#E1E4E8;">.layer3(x)</span></span>
<span class="line"><span style="color:#E1E4E8;">        x </span><span style="color:#F97583;">=</span><span style="color:#E1E4E8;"> </span><span style="color:#79B8FF;">self</span><span style="color:#E1E4E8;">.layer4(x)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#E1E4E8;">        </span><span style="color:#F97583;">if</span><span style="color:#E1E4E8;"> </span><span style="color:#79B8FF;">self</span><span style="color:#E1E4E8;">.include_top:</span></span>
<span class="line"><span style="color:#E1E4E8;">            x </span><span style="color:#F97583;">=</span><span style="color:#E1E4E8;"> </span><span style="color:#79B8FF;">self</span><span style="color:#E1E4E8;">.avgpool(x)</span></span>
<span class="line"><span style="color:#E1E4E8;">            x </span><span style="color:#F97583;">=</span><span style="color:#E1E4E8;"> torch.flatten(x, </span><span style="color:#79B8FF;">1</span><span style="color:#E1E4E8;">)</span></span>
<span class="line"><span style="color:#E1E4E8;">            x </span><span style="color:#F97583;">=</span><span style="color:#E1E4E8;"> </span><span style="color:#79B8FF;">self</span><span style="color:#E1E4E8;">.fc(x)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#E1E4E8;">        </span><span style="color:#F97583;">return</span><span style="color:#E1E4E8;"> x</span></span>
<span class="line"></span>
<span class="line"></span>
<span class="line"><span style="color:#F97583;">def</span><span style="color:#E1E4E8;"> </span><span style="color:#B392F0;">resnet34</span><span style="color:#E1E4E8;">(num_classes</span><span style="color:#F97583;">=</span><span style="color:#79B8FF;">1000</span><span style="color:#E1E4E8;">, include_top</span><span style="color:#F97583;">=</span><span style="color:#79B8FF;">True</span><span style="color:#E1E4E8;">):</span></span>
<span class="line"><span style="color:#E1E4E8;">    </span><span style="color:#F97583;">return</span><span style="color:#E1E4E8;"> ResNet(BasicBlock, [</span><span style="color:#79B8FF;">3</span><span style="color:#E1E4E8;">, </span><span style="color:#79B8FF;">4</span><span style="color:#E1E4E8;">, </span><span style="color:#79B8FF;">6</span><span style="color:#E1E4E8;">, </span><span style="color:#79B8FF;">3</span><span style="color:#E1E4E8;">], </span><span style="color:#FFAB70;">num_classes</span><span style="color:#F97583;">=</span><span style="color:#E1E4E8;">num_classes, </span><span style="color:#FFAB70;">include_top</span><span style="color:#F97583;">=</span><span style="color:#E1E4E8;">include_top)</span></span>
<span class="line"></span>
<span class="line"></span>
<span class="line"><span style="color:#F97583;">def</span><span style="color:#E1E4E8;"> </span><span style="color:#B392F0;">resnet101</span><span style="color:#E1E4E8;">(num_classes</span><span style="color:#F97583;">=</span><span style="color:#79B8FF;">1000</span><span style="color:#E1E4E8;">, include_top</span><span style="color:#F97583;">=</span><span style="color:#79B8FF;">True</span><span style="color:#E1E4E8;">):</span></span>
<span class="line"><span style="color:#E1E4E8;">    </span><span style="color:#F97583;">return</span><span style="color:#E1E4E8;"> ResNet(Bottleneck, [</span><span style="color:#79B8FF;">3</span><span style="color:#E1E4E8;">, </span><span style="color:#79B8FF;">4</span><span style="color:#E1E4E8;">, </span><span style="color:#79B8FF;">23</span><span style="color:#E1E4E8;">, </span><span style="color:#79B8FF;">3</span><span style="color:#E1E4E8;">], </span><span style="color:#FFAB70;">num_classes</span><span style="color:#F97583;">=</span><span style="color:#E1E4E8;">num_classes, </span><span style="color:#FFAB70;">include_top</span><span style="color:#F97583;">=</span><span style="color:#E1E4E8;">include_top)</span></span>
<span class="line"></span>
<span class="line"></span>
<span class="line"><span style="color:#9ECBFF;">&#39;&#39;&#39;</span></span>
<span class="line"><span style="color:#9ECBFF;">我们希望你能够去将论文下载下来以后跟一些讲解视频尝试将论文与代码结合起来理解</span></span>
<span class="line"><span style="color:#9ECBFF;">看论文的源码是我们必须要做的一个中重要的工作</span></span>
<span class="line"><span style="color:#9ECBFF;">&#39;&#39;&#39;</span></span></code></pre><pre class="shiki github-light vp-code-light"><code><span class="line"><span style="color:#D73A49;">import</span><span style="color:#24292E;"> torch.nn </span><span style="color:#D73A49;">as</span><span style="color:#24292E;"> nn</span></span>
<span class="line"><span style="color:#D73A49;">import</span><span style="color:#24292E;"> torch</span></span>
<span class="line"></span>
<span class="line"></span>
<span class="line"><span style="color:#6A737D;"># ResNet18/34的残差结构，用的是2个3x3的卷积</span></span>
<span class="line"><span style="color:#D73A49;">class</span><span style="color:#24292E;"> </span><span style="color:#6F42C1;">BasicBlock</span><span style="color:#24292E;">(</span><span style="color:#6F42C1;">nn</span><span style="color:#24292E;">.</span><span style="color:#6F42C1;">Module</span><span style="color:#24292E;">):</span></span>
<span class="line"><span style="color:#24292E;">    expansion </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">1</span><span style="color:#24292E;">  </span><span style="color:#6A737D;"># 残差结构中，主分支的卷积核个数是否发生变化，不变则为1</span></span>
<span class="line"></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#D73A49;">def</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">__init__</span><span style="color:#24292E;">(self, in_channel, out_channel, stride</span><span style="color:#D73A49;">=</span><span style="color:#005CC5;">1</span><span style="color:#24292E;">, downsample</span><span style="color:#D73A49;">=</span><span style="color:#005CC5;">None</span><span style="color:#24292E;">):  </span><span style="color:#6A737D;"># downsample对应虚线残差结构</span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#005CC5;">super</span><span style="color:#24292E;">(BasicBlock, </span><span style="color:#005CC5;">self</span><span style="color:#24292E;">).</span><span style="color:#005CC5;">__init__</span><span style="color:#24292E;">()</span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#005CC5;">self</span><span style="color:#24292E;">.conv1 </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> nn.Conv2d(</span><span style="color:#E36209;">in_channels</span><span style="color:#D73A49;">=</span><span style="color:#24292E;">in_channel, </span><span style="color:#E36209;">out_channels</span><span style="color:#D73A49;">=</span><span style="color:#24292E;">out_channel,</span></span>
<span class="line"><span style="color:#24292E;">                               </span><span style="color:#E36209;">kernel_size</span><span style="color:#D73A49;">=</span><span style="color:#005CC5;">3</span><span style="color:#24292E;">, </span><span style="color:#E36209;">stride</span><span style="color:#D73A49;">=</span><span style="color:#24292E;">stride, </span><span style="color:#E36209;">padding</span><span style="color:#D73A49;">=</span><span style="color:#005CC5;">1</span><span style="color:#24292E;">, </span><span style="color:#E36209;">bias</span><span style="color:#D73A49;">=</span><span style="color:#005CC5;">False</span><span style="color:#24292E;">)</span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#005CC5;">self</span><span style="color:#24292E;">.bn1 </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> nn.BatchNorm2d(out_channel)</span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#005CC5;">self</span><span style="color:#24292E;">.relu </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> nn.ReLU()</span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#005CC5;">self</span><span style="color:#24292E;">.conv2 </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> nn.Conv2d(</span><span style="color:#E36209;">in_channels</span><span style="color:#D73A49;">=</span><span style="color:#24292E;">out_channel, </span><span style="color:#E36209;">out_channels</span><span style="color:#D73A49;">=</span><span style="color:#24292E;">out_channel,</span></span>
<span class="line"><span style="color:#24292E;">                               </span><span style="color:#E36209;">kernel_size</span><span style="color:#D73A49;">=</span><span style="color:#005CC5;">3</span><span style="color:#24292E;">, </span><span style="color:#E36209;">stride</span><span style="color:#D73A49;">=</span><span style="color:#005CC5;">1</span><span style="color:#24292E;">, </span><span style="color:#E36209;">padding</span><span style="color:#D73A49;">=</span><span style="color:#005CC5;">1</span><span style="color:#24292E;">, </span><span style="color:#E36209;">bias</span><span style="color:#D73A49;">=</span><span style="color:#005CC5;">False</span><span style="color:#24292E;">)</span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#005CC5;">self</span><span style="color:#24292E;">.bn2 </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> nn.BatchNorm2d(out_channel)</span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#005CC5;">self</span><span style="color:#24292E;">.downsample </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> downsample</span></span>
<span class="line"></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#D73A49;">def</span><span style="color:#24292E;"> </span><span style="color:#6F42C1;">forward</span><span style="color:#24292E;">(self, x):</span></span>
<span class="line"><span style="color:#24292E;">        identity </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> x</span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#D73A49;">if</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">self</span><span style="color:#24292E;">.downsample </span><span style="color:#D73A49;">is</span><span style="color:#24292E;"> </span><span style="color:#D73A49;">not</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">None</span><span style="color:#24292E;">:  </span><span style="color:#6A737D;"># 虚线残差结构，需要下采样</span></span>
<span class="line"><span style="color:#24292E;">            identity </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">self</span><span style="color:#24292E;">.downsample(x)  </span><span style="color:#6A737D;"># 捷径分支 short cut</span></span>
<span class="line"></span>
<span class="line"><span style="color:#24292E;">        out </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">self</span><span style="color:#24292E;">.conv1(x)</span></span>
<span class="line"><span style="color:#24292E;">        out </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">self</span><span style="color:#24292E;">.bn1(out)</span></span>
<span class="line"><span style="color:#24292E;">        out </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">self</span><span style="color:#24292E;">.relu(out)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#24292E;">        out </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">self</span><span style="color:#24292E;">.conv2(out)</span></span>
<span class="line"><span style="color:#24292E;">        out </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">self</span><span style="color:#24292E;">.bn2(out)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#24292E;">        out </span><span style="color:#D73A49;">+=</span><span style="color:#24292E;"> identity</span></span>
<span class="line"><span style="color:#24292E;">        out </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">self</span><span style="color:#24292E;">.relu(out)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#D73A49;">return</span><span style="color:#24292E;"> out</span></span>
<span class="line"></span>
<span class="line"><span style="color:#6A737D;"># ResNet50/101/152的残差结构，用的是1x1+3x3+1x1的卷积</span></span>
<span class="line"><span style="color:#D73A49;">class</span><span style="color:#24292E;"> </span><span style="color:#6F42C1;">Bottleneck</span><span style="color:#24292E;">(</span><span style="color:#6F42C1;">nn</span><span style="color:#24292E;">.</span><span style="color:#6F42C1;">Module</span><span style="color:#24292E;">):</span></span>
<span class="line"><span style="color:#24292E;">    expansion </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">4</span><span style="color:#24292E;">  </span><span style="color:#6A737D;"># 残差结构中第三层卷积核个数是第一/二层卷积核个数的4倍</span></span>
<span class="line"></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#D73A49;">def</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">__init__</span><span style="color:#24292E;">(self, in_channel, out_channel, stride</span><span style="color:#D73A49;">=</span><span style="color:#005CC5;">1</span><span style="color:#24292E;">, downsample</span><span style="color:#D73A49;">=</span><span style="color:#005CC5;">None</span><span style="color:#24292E;">):</span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#005CC5;">super</span><span style="color:#24292E;">(Bottleneck, </span><span style="color:#005CC5;">self</span><span style="color:#24292E;">).</span><span style="color:#005CC5;">__init__</span><span style="color:#24292E;">()</span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#005CC5;">self</span><span style="color:#24292E;">.conv1 </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> nn.Conv2d(</span><span style="color:#E36209;">in_channels</span><span style="color:#D73A49;">=</span><span style="color:#24292E;">in_channel, </span><span style="color:#E36209;">out_channels</span><span style="color:#D73A49;">=</span><span style="color:#24292E;">out_channel,</span></span>
<span class="line"><span style="color:#24292E;">                               </span><span style="color:#E36209;">kernel_size</span><span style="color:#D73A49;">=</span><span style="color:#005CC5;">1</span><span style="color:#24292E;">, </span><span style="color:#E36209;">stride</span><span style="color:#D73A49;">=</span><span style="color:#005CC5;">1</span><span style="color:#24292E;">, </span><span style="color:#E36209;">bias</span><span style="color:#D73A49;">=</span><span style="color:#005CC5;">False</span><span style="color:#24292E;">)  </span><span style="color:#6A737D;"># squeeze channels</span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#005CC5;">self</span><span style="color:#24292E;">.bn1 </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> nn.BatchNorm2d(out_channel)</span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#6A737D;"># -----------------------------------------</span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#005CC5;">self</span><span style="color:#24292E;">.conv2 </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> nn.Conv2d(</span><span style="color:#E36209;">in_channels</span><span style="color:#D73A49;">=</span><span style="color:#24292E;">out_channel, </span><span style="color:#E36209;">out_channels</span><span style="color:#D73A49;">=</span><span style="color:#24292E;">out_channel,</span></span>
<span class="line"><span style="color:#24292E;">                               </span><span style="color:#E36209;">kernel_size</span><span style="color:#D73A49;">=</span><span style="color:#005CC5;">3</span><span style="color:#24292E;">, </span><span style="color:#E36209;">stride</span><span style="color:#D73A49;">=</span><span style="color:#24292E;">stride, </span><span style="color:#E36209;">bias</span><span style="color:#D73A49;">=</span><span style="color:#005CC5;">False</span><span style="color:#24292E;">, </span><span style="color:#E36209;">padding</span><span style="color:#D73A49;">=</span><span style="color:#005CC5;">1</span><span style="color:#24292E;">)</span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#005CC5;">self</span><span style="color:#24292E;">.bn2 </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> nn.BatchNorm2d(out_channel)</span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#6A737D;"># -----------------------------------------</span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#005CC5;">self</span><span style="color:#24292E;">.conv3 </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> nn.Conv2d(</span><span style="color:#E36209;">in_channels</span><span style="color:#D73A49;">=</span><span style="color:#24292E;">out_channel, </span><span style="color:#E36209;">out_channels</span><span style="color:#D73A49;">=</span><span style="color:#24292E;">out_channel </span><span style="color:#D73A49;">*</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">self</span><span style="color:#24292E;">.expansion,</span></span>
<span class="line"><span style="color:#24292E;">                               </span><span style="color:#E36209;">kernel_size</span><span style="color:#D73A49;">=</span><span style="color:#005CC5;">1</span><span style="color:#24292E;">, </span><span style="color:#E36209;">stride</span><span style="color:#D73A49;">=</span><span style="color:#005CC5;">1</span><span style="color:#24292E;">, </span><span style="color:#E36209;">bias</span><span style="color:#D73A49;">=</span><span style="color:#005CC5;">False</span><span style="color:#24292E;">)  </span><span style="color:#6A737D;"># unsqueeze channels</span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#005CC5;">self</span><span style="color:#24292E;">.bn3 </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> nn.BatchNorm2d(out_channel </span><span style="color:#D73A49;">*</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">self</span><span style="color:#24292E;">.expansion)</span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#005CC5;">self</span><span style="color:#24292E;">.relu </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> nn.ReLU(</span><span style="color:#E36209;">inplace</span><span style="color:#D73A49;">=</span><span style="color:#005CC5;">True</span><span style="color:#24292E;">)</span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#005CC5;">self</span><span style="color:#24292E;">.downsample </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> downsample</span></span>
<span class="line"></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#D73A49;">def</span><span style="color:#24292E;"> </span><span style="color:#6F42C1;">forward</span><span style="color:#24292E;">(self, x):</span></span>
<span class="line"><span style="color:#24292E;">        identity </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> x</span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#D73A49;">if</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">self</span><span style="color:#24292E;">.downsample </span><span style="color:#D73A49;">is</span><span style="color:#24292E;"> </span><span style="color:#D73A49;">not</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">None</span><span style="color:#24292E;">:</span></span>
<span class="line"><span style="color:#24292E;">            identity </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">self</span><span style="color:#24292E;">.downsample(x)  </span><span style="color:#6A737D;"># 捷径分支 short cut</span></span>
<span class="line"></span>
<span class="line"><span style="color:#24292E;">        out </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">self</span><span style="color:#24292E;">.conv1(x)</span></span>
<span class="line"><span style="color:#24292E;">        out </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">self</span><span style="color:#24292E;">.bn1(out)</span></span>
<span class="line"><span style="color:#24292E;">        out </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">self</span><span style="color:#24292E;">.relu(out)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#24292E;">        out </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">self</span><span style="color:#24292E;">.conv2(out)</span></span>
<span class="line"><span style="color:#24292E;">        out </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">self</span><span style="color:#24292E;">.bn2(out)</span></span>
<span class="line"><span style="color:#24292E;">        out </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">self</span><span style="color:#24292E;">.relu(out)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#24292E;">        out </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">self</span><span style="color:#24292E;">.conv3(out)</span></span>
<span class="line"><span style="color:#24292E;">        out </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">self</span><span style="color:#24292E;">.bn3(out)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#24292E;">        out </span><span style="color:#D73A49;">+=</span><span style="color:#24292E;"> identity</span></span>
<span class="line"><span style="color:#24292E;">        out </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">self</span><span style="color:#24292E;">.relu(out)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#D73A49;">return</span><span style="color:#24292E;"> out</span></span>
<span class="line"></span>
<span class="line"></span>
<span class="line"><span style="color:#D73A49;">class</span><span style="color:#24292E;"> </span><span style="color:#6F42C1;">ResNet</span><span style="color:#24292E;">(</span><span style="color:#6F42C1;">nn</span><span style="color:#24292E;">.</span><span style="color:#6F42C1;">Module</span><span style="color:#24292E;">):</span></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#6A737D;"># block = BasicBlock or Bottleneck</span></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#6A737D;"># block_num为残差结构中conv2_x~conv5_x中残差块个数，是一个列表</span></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#D73A49;">def</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">__init__</span><span style="color:#24292E;">(self, block, blocks_num, num_classes</span><span style="color:#D73A49;">=</span><span style="color:#005CC5;">1000</span><span style="color:#24292E;">, include_top</span><span style="color:#D73A49;">=</span><span style="color:#005CC5;">True</span><span style="color:#24292E;">):</span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#005CC5;">super</span><span style="color:#24292E;">(ResNet, </span><span style="color:#005CC5;">self</span><span style="color:#24292E;">).</span><span style="color:#005CC5;">__init__</span><span style="color:#24292E;">()</span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#005CC5;">self</span><span style="color:#24292E;">.include_top </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> include_top</span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#005CC5;">self</span><span style="color:#24292E;">.in_channel </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">64</span></span>
<span class="line"></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#005CC5;">self</span><span style="color:#24292E;">.conv1 </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> nn.Conv2d(</span><span style="color:#005CC5;">3</span><span style="color:#24292E;">, </span><span style="color:#005CC5;">self</span><span style="color:#24292E;">.in_channel, </span><span style="color:#E36209;">kernel_size</span><span style="color:#D73A49;">=</span><span style="color:#005CC5;">7</span><span style="color:#24292E;">, </span><span style="color:#E36209;">stride</span><span style="color:#D73A49;">=</span><span style="color:#005CC5;">2</span><span style="color:#24292E;">,</span></span>
<span class="line"><span style="color:#24292E;">                               </span><span style="color:#E36209;">padding</span><span style="color:#D73A49;">=</span><span style="color:#005CC5;">3</span><span style="color:#24292E;">, </span><span style="color:#E36209;">bias</span><span style="color:#D73A49;">=</span><span style="color:#005CC5;">False</span><span style="color:#24292E;">)</span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#005CC5;">self</span><span style="color:#24292E;">.bn1 </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> nn.BatchNorm2d(</span><span style="color:#005CC5;">self</span><span style="color:#24292E;">.in_channel)</span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#005CC5;">self</span><span style="color:#24292E;">.relu </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> nn.ReLU(</span><span style="color:#E36209;">inplace</span><span style="color:#D73A49;">=</span><span style="color:#005CC5;">True</span><span style="color:#24292E;">)</span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#005CC5;">self</span><span style="color:#24292E;">.maxpool </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> nn.MaxPool2d(</span><span style="color:#E36209;">kernel_size</span><span style="color:#D73A49;">=</span><span style="color:#005CC5;">3</span><span style="color:#24292E;">, </span><span style="color:#E36209;">stride</span><span style="color:#D73A49;">=</span><span style="color:#005CC5;">2</span><span style="color:#24292E;">, </span><span style="color:#E36209;">padding</span><span style="color:#D73A49;">=</span><span style="color:#005CC5;">1</span><span style="color:#24292E;">)</span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#005CC5;">self</span><span style="color:#24292E;">.layer1 </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">self</span><span style="color:#24292E;">._make_layer(block, </span><span style="color:#005CC5;">64</span><span style="color:#24292E;">, blocks_num[</span><span style="color:#005CC5;">0</span><span style="color:#24292E;">])             </span><span style="color:#6A737D;"># conv2_x</span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#005CC5;">self</span><span style="color:#24292E;">.layer2 </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">self</span><span style="color:#24292E;">._make_layer(block, </span><span style="color:#005CC5;">128</span><span style="color:#24292E;">, blocks_num[</span><span style="color:#005CC5;">1</span><span style="color:#24292E;">], </span><span style="color:#E36209;">stride</span><span style="color:#D73A49;">=</span><span style="color:#005CC5;">2</span><span style="color:#24292E;">)  </span><span style="color:#6A737D;"># conv3_x</span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#005CC5;">self</span><span style="color:#24292E;">.layer3 </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">self</span><span style="color:#24292E;">._make_layer(block, </span><span style="color:#005CC5;">256</span><span style="color:#24292E;">, blocks_num[</span><span style="color:#005CC5;">2</span><span style="color:#24292E;">], </span><span style="color:#E36209;">stride</span><span style="color:#D73A49;">=</span><span style="color:#005CC5;">2</span><span style="color:#24292E;">)  </span><span style="color:#6A737D;"># conv4_x</span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#005CC5;">self</span><span style="color:#24292E;">.layer4 </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">self</span><span style="color:#24292E;">._make_layer(block, </span><span style="color:#005CC5;">512</span><span style="color:#24292E;">, blocks_num[</span><span style="color:#005CC5;">3</span><span style="color:#24292E;">], </span><span style="color:#E36209;">stride</span><span style="color:#D73A49;">=</span><span style="color:#005CC5;">2</span><span style="color:#24292E;">)  </span><span style="color:#6A737D;"># conv5_x</span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#D73A49;">if</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">self</span><span style="color:#24292E;">.include_top:</span></span>
<span class="line"><span style="color:#24292E;">            </span><span style="color:#005CC5;">self</span><span style="color:#24292E;">.avgpool </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> nn.AdaptiveAvgPool2d((</span><span style="color:#005CC5;">1</span><span style="color:#24292E;">, </span><span style="color:#005CC5;">1</span><span style="color:#24292E;">))  </span><span style="color:#6A737D;"># output size = (1, 1)</span></span>
<span class="line"><span style="color:#24292E;">            </span><span style="color:#005CC5;">self</span><span style="color:#24292E;">.fc </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> nn.Linear(</span><span style="color:#005CC5;">512</span><span style="color:#24292E;"> </span><span style="color:#D73A49;">*</span><span style="color:#24292E;"> block.expansion, num_classes)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#D73A49;">for</span><span style="color:#24292E;"> m </span><span style="color:#D73A49;">in</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">self</span><span style="color:#24292E;">.modules():</span></span>
<span class="line"><span style="color:#24292E;">            </span><span style="color:#D73A49;">if</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">isinstance</span><span style="color:#24292E;">(m, nn.Conv2d):</span></span>
<span class="line"><span style="color:#24292E;">                nn.init.kaiming_normal_(m.weight, </span><span style="color:#E36209;">mode</span><span style="color:#D73A49;">=</span><span style="color:#032F62;">&#39;fan_out&#39;</span><span style="color:#24292E;">, </span><span style="color:#E36209;">nonlinearity</span><span style="color:#D73A49;">=</span><span style="color:#032F62;">&#39;relu&#39;</span><span style="color:#24292E;">)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#6A737D;"># channel为残差结构中第一层卷积核个数</span></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#D73A49;">def</span><span style="color:#24292E;"> </span><span style="color:#6F42C1;">_make_layer</span><span style="color:#24292E;">(self, block, channel, block_num, stride</span><span style="color:#D73A49;">=</span><span style="color:#005CC5;">1</span><span style="color:#24292E;">):</span></span>
<span class="line"><span style="color:#24292E;">        downsample </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">None</span></span>
<span class="line"></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#6A737D;"># ResNet50/101/152的残差结构，block.expansion=4</span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#D73A49;">if</span><span style="color:#24292E;"> stride </span><span style="color:#D73A49;">!=</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">1</span><span style="color:#24292E;"> </span><span style="color:#D73A49;">or</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">self</span><span style="color:#24292E;">.in_channel </span><span style="color:#D73A49;">!=</span><span style="color:#24292E;"> channel </span><span style="color:#D73A49;">*</span><span style="color:#24292E;"> block.expansion:</span></span>
<span class="line"><span style="color:#24292E;">            downsample </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> nn.Sequential(</span></span>
<span class="line"><span style="color:#24292E;">                nn.Conv2d(</span><span style="color:#005CC5;">self</span><span style="color:#24292E;">.in_channel, channel </span><span style="color:#D73A49;">*</span><span style="color:#24292E;"> block.expansion, </span><span style="color:#E36209;">kernel_size</span><span style="color:#D73A49;">=</span><span style="color:#005CC5;">1</span><span style="color:#24292E;">, </span><span style="color:#E36209;">stride</span><span style="color:#D73A49;">=</span><span style="color:#24292E;">stride, </span><span style="color:#E36209;">bias</span><span style="color:#D73A49;">=</span><span style="color:#005CC5;">False</span><span style="color:#24292E;">),</span></span>
<span class="line"><span style="color:#24292E;">                nn.BatchNorm2d(channel </span><span style="color:#D73A49;">*</span><span style="color:#24292E;"> block.expansion))</span></span>
<span class="line"></span>
<span class="line"><span style="color:#24292E;">        layers </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> []</span></span>
<span class="line"><span style="color:#24292E;">        layers.append(block(</span><span style="color:#005CC5;">self</span><span style="color:#24292E;">.in_channel, channel, </span><span style="color:#E36209;">downsample</span><span style="color:#D73A49;">=</span><span style="color:#24292E;">downsample, </span><span style="color:#E36209;">stride</span><span style="color:#D73A49;">=</span><span style="color:#24292E;">stride))</span></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#005CC5;">self</span><span style="color:#24292E;">.in_channel </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> channel </span><span style="color:#D73A49;">*</span><span style="color:#24292E;"> block.expansion</span></span>
<span class="line"></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#D73A49;">for</span><span style="color:#24292E;"> _ </span><span style="color:#D73A49;">in</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">range</span><span style="color:#24292E;">(</span><span style="color:#005CC5;">1</span><span style="color:#24292E;">, block_num):</span></span>
<span class="line"><span style="color:#24292E;">            layers.append(block(</span><span style="color:#005CC5;">self</span><span style="color:#24292E;">.in_channel, channel))</span></span>
<span class="line"></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#D73A49;">return</span><span style="color:#24292E;"> nn.Sequential(</span><span style="color:#D73A49;">*</span><span style="color:#24292E;">layers)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#D73A49;">def</span><span style="color:#24292E;"> </span><span style="color:#6F42C1;">forward</span><span style="color:#24292E;">(self, x):</span></span>
<span class="line"><span style="color:#24292E;">        x </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">self</span><span style="color:#24292E;">.conv1(x)</span></span>
<span class="line"><span style="color:#24292E;">        x </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">self</span><span style="color:#24292E;">.bn1(x)</span></span>
<span class="line"><span style="color:#24292E;">        x </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">self</span><span style="color:#24292E;">.relu(x)</span></span>
<span class="line"><span style="color:#24292E;">        x </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">self</span><span style="color:#24292E;">.maxpool(x)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#24292E;">        x </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">self</span><span style="color:#24292E;">.layer1(x)</span></span>
<span class="line"><span style="color:#24292E;">        x </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">self</span><span style="color:#24292E;">.layer2(x)</span></span>
<span class="line"><span style="color:#24292E;">        x </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">self</span><span style="color:#24292E;">.layer3(x)</span></span>
<span class="line"><span style="color:#24292E;">        x </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">self</span><span style="color:#24292E;">.layer4(x)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#D73A49;">if</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">self</span><span style="color:#24292E;">.include_top:</span></span>
<span class="line"><span style="color:#24292E;">            x </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">self</span><span style="color:#24292E;">.avgpool(x)</span></span>
<span class="line"><span style="color:#24292E;">            x </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> torch.flatten(x, </span><span style="color:#005CC5;">1</span><span style="color:#24292E;">)</span></span>
<span class="line"><span style="color:#24292E;">            x </span><span style="color:#D73A49;">=</span><span style="color:#24292E;"> </span><span style="color:#005CC5;">self</span><span style="color:#24292E;">.fc(x)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#24292E;">        </span><span style="color:#D73A49;">return</span><span style="color:#24292E;"> x</span></span>
<span class="line"></span>
<span class="line"></span>
<span class="line"><span style="color:#D73A49;">def</span><span style="color:#24292E;"> </span><span style="color:#6F42C1;">resnet34</span><span style="color:#24292E;">(num_classes</span><span style="color:#D73A49;">=</span><span style="color:#005CC5;">1000</span><span style="color:#24292E;">, include_top</span><span style="color:#D73A49;">=</span><span style="color:#005CC5;">True</span><span style="color:#24292E;">):</span></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#D73A49;">return</span><span style="color:#24292E;"> ResNet(BasicBlock, [</span><span style="color:#005CC5;">3</span><span style="color:#24292E;">, </span><span style="color:#005CC5;">4</span><span style="color:#24292E;">, </span><span style="color:#005CC5;">6</span><span style="color:#24292E;">, </span><span style="color:#005CC5;">3</span><span style="color:#24292E;">], </span><span style="color:#E36209;">num_classes</span><span style="color:#D73A49;">=</span><span style="color:#24292E;">num_classes, </span><span style="color:#E36209;">include_top</span><span style="color:#D73A49;">=</span><span style="color:#24292E;">include_top)</span></span>
<span class="line"></span>
<span class="line"></span>
<span class="line"><span style="color:#D73A49;">def</span><span style="color:#24292E;"> </span><span style="color:#6F42C1;">resnet101</span><span style="color:#24292E;">(num_classes</span><span style="color:#D73A49;">=</span><span style="color:#005CC5;">1000</span><span style="color:#24292E;">, include_top</span><span style="color:#D73A49;">=</span><span style="color:#005CC5;">True</span><span style="color:#24292E;">):</span></span>
<span class="line"><span style="color:#24292E;">    </span><span style="color:#D73A49;">return</span><span style="color:#24292E;"> ResNet(Bottleneck, [</span><span style="color:#005CC5;">3</span><span style="color:#24292E;">, </span><span style="color:#005CC5;">4</span><span style="color:#24292E;">, </span><span style="color:#005CC5;">23</span><span style="color:#24292E;">, </span><span style="color:#005CC5;">3</span><span style="color:#24292E;">], </span><span style="color:#E36209;">num_classes</span><span style="color:#D73A49;">=</span><span style="color:#24292E;">num_classes, </span><span style="color:#E36209;">include_top</span><span style="color:#D73A49;">=</span><span style="color:#24292E;">include_top)</span></span>
<span class="line"></span>
<span class="line"></span>
<span class="line"><span style="color:#032F62;">&#39;&#39;&#39;</span></span>
<span class="line"><span style="color:#032F62;">我们希望你能够去将论文下载下来以后跟一些讲解视频尝试将论文与代码结合起来理解</span></span>
<span class="line"><span style="color:#032F62;">看论文的源码是我们必须要做的一个中重要的工作</span></span>
<span class="line"><span style="color:#032F62;">&#39;&#39;&#39;</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br><span class="line-number">21</span><br><span class="line-number">22</span><br><span class="line-number">23</span><br><span class="line-number">24</span><br><span class="line-number">25</span><br><span class="line-number">26</span><br><span class="line-number">27</span><br><span class="line-number">28</span><br><span class="line-number">29</span><br><span class="line-number">30</span><br><span class="line-number">31</span><br><span class="line-number">32</span><br><span class="line-number">33</span><br><span class="line-number">34</span><br><span class="line-number">35</span><br><span class="line-number">36</span><br><span class="line-number">37</span><br><span class="line-number">38</span><br><span class="line-number">39</span><br><span class="line-number">40</span><br><span class="line-number">41</span><br><span class="line-number">42</span><br><span class="line-number">43</span><br><span class="line-number">44</span><br><span class="line-number">45</span><br><span class="line-number">46</span><br><span class="line-number">47</span><br><span class="line-number">48</span><br><span class="line-number">49</span><br><span class="line-number">50</span><br><span class="line-number">51</span><br><span class="line-number">52</span><br><span class="line-number">53</span><br><span class="line-number">54</span><br><span class="line-number">55</span><br><span class="line-number">56</span><br><span class="line-number">57</span><br><span class="line-number">58</span><br><span class="line-number">59</span><br><span class="line-number">60</span><br><span class="line-number">61</span><br><span class="line-number">62</span><br><span class="line-number">63</span><br><span class="line-number">64</span><br><span class="line-number">65</span><br><span class="line-number">66</span><br><span class="line-number">67</span><br><span class="line-number">68</span><br><span class="line-number">69</span><br><span class="line-number">70</span><br><span class="line-number">71</span><br><span class="line-number">72</span><br><span class="line-number">73</span><br><span class="line-number">74</span><br><span class="line-number">75</span><br><span class="line-number">76</span><br><span class="line-number">77</span><br><span class="line-number">78</span><br><span class="line-number">79</span><br><span class="line-number">80</span><br><span class="line-number">81</span><br><span class="line-number">82</span><br><span class="line-number">83</span><br><span class="line-number">84</span><br><span class="line-number">85</span><br><span class="line-number">86</span><br><span class="line-number">87</span><br><span class="line-number">88</span><br><span class="line-number">89</span><br><span class="line-number">90</span><br><span class="line-number">91</span><br><span class="line-number">92</span><br><span class="line-number">93</span><br><span class="line-number">94</span><br><span class="line-number">95</span><br><span class="line-number">96</span><br><span class="line-number">97</span><br><span class="line-number">98</span><br><span class="line-number">99</span><br><span class="line-number">100</span><br><span class="line-number">101</span><br><span class="line-number">102</span><br><span class="line-number">103</span><br><span class="line-number">104</span><br><span class="line-number">105</span><br><span class="line-number">106</span><br><span class="line-number">107</span><br><span class="line-number">108</span><br><span class="line-number">109</span><br><span class="line-number">110</span><br><span class="line-number">111</span><br><span class="line-number">112</span><br><span class="line-number">113</span><br><span class="line-number">114</span><br><span class="line-number">115</span><br><span class="line-number">116</span><br><span class="line-number">117</span><br><span class="line-number">118</span><br><span class="line-number">119</span><br><span class="line-number">120</span><br><span class="line-number">121</span><br><span class="line-number">122</span><br><span class="line-number">123</span><br><span class="line-number">124</span><br><span class="line-number">125</span><br><span class="line-number">126</span><br><span class="line-number">127</span><br><span class="line-number">128</span><br><span class="line-number">129</span><br><span class="line-number">130</span><br><span class="line-number">131</span><br><span class="line-number">132</span><br><span class="line-number">133</span><br><span class="line-number">134</span><br><span class="line-number">135</span><br><span class="line-number">136</span><br><span class="line-number">137</span><br><span class="line-number">138</span><br><span class="line-number">139</span><br><span class="line-number">140</span><br><span class="line-number">141</span><br><span class="line-number">142</span><br><span class="line-number">143</span><br><span class="line-number">144</span><br><span class="line-number">145</span><br><span class="line-number">146</span><br><span class="line-number">147</span><br><span class="line-number">148</span><br><span class="line-number">149</span><br><span class="line-number">150</span><br><span class="line-number">151</span><br><span class="line-number">152</span><br><span class="line-number">153</span><br></div></div><h2 id="视频" tabindex="-1">视频 <a class="header-anchor" href="#视频" aria-label="Permalink to &quot;视频&quot;">​</a></h2>`,15),t=s('<h2 id="思考" tabindex="-1">思考 <a class="header-anchor" href="#思考" aria-label="Permalink to &quot;思考&quot;">​</a></h2><h3 id="思考-1" tabindex="-1">思考 1 <a class="header-anchor" href="#思考-1" aria-label="Permalink to &quot;思考 1&quot;">​</a></h3><div class="warning custom-block"><p class="custom-block-title">🤔</p><p>请你自行了解网络结构中的 BN（Batch Normalization）层，这是很重要的一个 normalization 操作，如果感兴趣还可以继续了解 LN (Layer Normalization)</p></div><h3 id="思考-2" tabindex="-1">思考 2 <a class="header-anchor" href="#思考-2" aria-label="Permalink to &quot;思考 2&quot;">​</a></h3><div class="warning custom-block"><p class="custom-block-title">🤔</p><p>你觉得论文中提出用 residual 这一解决方法来解决网络的退化现象的依据是什么，如果可以，请你进一步尝试用数学角度思考这一问题</p></div>',5);function y(E,i,F,u,b,C){const n=l("Bilibili");return p(),o("div",null,[r,e(n,{bvid:"BV1P3411y7nn"}),t])}const _=a(c,[["render",y]]);export{d as __pageData,_ as default};
