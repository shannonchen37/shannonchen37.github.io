import{_ as o,I as n,o as Q,c as T,x as l,j as t,a as e,U as a}from"./chunks/framework.489e5108.js";const v=JSON.parse('{"title":"深度学习快速入门","description":"","frontmatter":{},"headers":[],"relativePath":"4.人工智能/4.6.3深度学习快速入门.md","filePath":"4.人工智能/4.6.3深度学习快速入门.md","lastUpdated":1696176798000}'),s={name:"4.人工智能/4.6.3深度学习快速入门.md"},i=a('<h1 id="深度学习快速入门" tabindex="-1">深度学习快速入门 <a class="header-anchor" href="#深度学习快速入门" aria-label="Permalink to &quot;深度学习快速入门&quot;">​</a></h1><h2 id="刘二大人-pytorch" tabindex="-1"><strong>刘二大人 (Pytorch)</strong> <a class="header-anchor" href="#刘二大人-pytorch" aria-label="Permalink to &quot;**刘二大人(Pytorch)**&quot;">​</a></h2><h2 id="速成课-人工智能" tabindex="-1">速成课：人工智能 <a class="header-anchor" href="#速成课-人工智能" aria-label="Permalink to &quot;速成课：人工智能&quot;">​</a></h2><p><a href="https://www.bilibili.com/video/BV1P7411r7Dw" target="_blank" rel="noreferrer">【速成课：人工智能】Ai - [21 集全 / 中英双语] - Artificial Intelligence_哔哩哔哩_bilibili</a></p>',4),h=a('<p>Crash course 的课程，可以基本了解 pytorch 的内容，但是当然有很多内容已经有些过时</p><h1 id="这是啥" tabindex="-1">这是啥？ <a class="header-anchor" href="#这是啥" aria-label="Permalink to &quot;这是啥？&quot;">​</a></h1><p>这是一个快速入门深度学习的途径。</p><h1 id="课程大概讲了啥" tabindex="-1">课程大概讲了啥？ <a class="header-anchor" href="#课程大概讲了啥" aria-label="Permalink to &quot;课程大概讲了啥？&quot;">​</a></h1><p>刘二大人的深度学习是用来给小白快速上手用的。其中介绍了大概的深度学习框架，基本的几种损失函数，激活函数，网络。</p><p>课程中用到了 3 个数据集：糖尿病数据集，泰坦尼克号数据集，和最经典的 MINIST 数据集。其中我们只需要用到 MINIST 数据集，其他两个如果有兴趣可以去尝试。我们最快可以在 1 个星期内训练出我们的第一个模型用来识别手写数字，初窥人工智能的门槛。</p><p>这个课程最主要的是着重讲解了大致的框架，深度学习的代码就像搭积木一样，当大致的框架有了，剩下的就只剩下往里面塞东西就好了。当我们学习了刘二大人的课程之后，一些基本的任务都可以用这些基本的网络简单解决。</p><h1 id="学习这系列视频需要哪些前置条件" tabindex="-1">学习这系列视频需要哪些前置条件？ <a class="header-anchor" href="#学习这系列视频需要哪些前置条件" aria-label="Permalink to &quot;学习这系列视频需要哪些前置条件？&quot;">​</a></h1><h2 id="python" tabindex="-1">python <a class="header-anchor" href="#python" aria-label="Permalink to &quot;python&quot;">​</a></h2><p>基本的一些 python 知识，你可以在本讲义中的 <a href="./../3.编程思维体系构建/3.6Python（灵巧的胶水）">3.6python 模块</a>中进行简单的学习。解决其中的题目大致就可以了，之后遇到不会的只要去 Google 一下，或者去问问 ChatGPT，问问 New Bing。</p><h2 id="pycharm-pytorch-anaconda-等环境配置" tabindex="-1">pycharm,pytorch,anaconda 等环境配置 <a class="header-anchor" href="#pycharm-pytorch-anaconda-等环境配置" aria-label="Permalink to &quot;pycharm,pytorch,anaconda 等环境配置&quot;">​</a></h2><p>你可以在本讲义中的 <a href="./../4.人工智能/4.6.4Pytorch安装">Pytorch 安装</a>中找到怎么配置 pytorch，你可以在这里安装 <a href="https://www.jetbrains.com/zh-cn/pycharm/" target="_blank" rel="noreferrer">Pycharm</a>。</p><p>你可以在本讲义中的 <a href="./../3.编程思维体系构建/3.6.3安装python">python 安装</a>中找到 Pycharm 和 anaconda 的安装教学视频</p><h2 id="一个找乐子的心" tabindex="-1">一个找乐子的心 <a class="header-anchor" href="#一个找乐子的心" aria-label="Permalink to &quot;一个找乐子的心&quot;">​</a></h2><p>如果觉得它好玩的话，就去学吧。</p><h2 id="前置知识" tabindex="-1">前置知识？ <a class="header-anchor" href="#前置知识" aria-label="Permalink to &quot;前置知识？&quot;">​</a></h2><p>要啥前置知识，这就是给你入门用的。如果你不打无准备的仗，你可以简单看看<a href="./4.2机器学习（AI）快速入门（quick start）">机器学习快速入门</a>。</p><h1 id="学完课程之后可能出现的问题" tabindex="-1">学完课程之后可能出现的问题 <a class="header-anchor" href="#学完课程之后可能出现的问题" aria-label="Permalink to &quot;学完课程之后可能出现的问题&quot;">​</a></h1><p>通过这个课程虽然我们可以进行快速入门，但经过我个人的入门实践表明，视频中没有告诉你完整的数学推导，也懒得进行公式推导，所以在观看这门教程之后虽然已经会基本的 coding 能力了但是基础并不扎实。</p><p>我们不知道每一个给你封装好的函数具体在干什么，不知道经过这个线性层，经过这个卷积操作出来的特征大致对应着什么，它们对我们来说确实变成了一个黑盒。我们只知道：欸，我就这么一写，in_feature 和 out_feature 写对了，程序成功运行了，正确率有 80% 多欸，我已经会深度学习了。</p><p>所以在这门课程结束之后建议手写其中的一些封装好的函数，比如一些基础的线性层。尝试画个图，像课程中刘二讲给我们的那样，看看大致的流程，每一层出来的特征大致代表着什么。</p><h1 id="你还有疑惑" tabindex="-1">你还有疑惑？ <a class="header-anchor" href="#你还有疑惑" aria-label="Permalink to &quot;你还有疑惑？&quot;">​</a></h1><p>你可以通过以下方式解决你对于此课程的疑惑：</p><h2 id="基础知识的疑惑" tabindex="-1">基础知识的疑惑 <a class="header-anchor" href="#基础知识的疑惑" aria-label="Permalink to &quot;基础知识的疑惑&quot;">​</a></h2><p>如果你对于课程中的一些基本知识比如说梯度下降算法等感到疑惑，你可以移步<a href="./4.2机器学习（AI）快速入门（quick start）">机器学习快速入门</a></p><p>当然，在这里我会简单的为你讲解一下最基础最关键的算法：梯度下降算法。和怎么快速理解计算机为什么能识别手写数字。</p><h2 id="torch-我还不会呢" tabindex="-1">torch 我还不会呢！ <a class="header-anchor" href="#torch-我还不会呢" aria-label="Permalink to &quot;torch 我还不会呢！&quot;">​</a></h2><p>学会一个<strong>庞大并且高度封装</strong>的包并不是一蹴而就的，我们建议从实践开始，比如说自己搭建一个神经网络来实现 MNIST 的分类。在使用这些函数和类的过程中你能更快地掌握它们的方法。</p><h1 id="关于梯度下降算法" tabindex="-1">关于梯度下降算法： <a class="header-anchor" href="#关于梯度下降算法" aria-label="Permalink to &quot;关于梯度下降算法：&quot;">​</a></h1><h3 id="损失" tabindex="-1">损失 <a class="header-anchor" href="#损失" aria-label="Permalink to &quot;损失&quot;">​</a></h3><p><img src="https://cdn.xyxsw.site/boxcnRbeabbEppeHlM39UwqJSJc.png" alt=""></p>',31),d={class:"MathJax",jax:"SVG",style:{direction:"ltr",position:"relative"}},m={style:{overflow:"visible","min-height":"1px","min-width":"1px","vertical-align":"-0.452ex"},xmlns:"http://www.w3.org/2000/svg",width:"28.005ex",height:"2.149ex",role:"img",focusable:"false",viewBox:"0 -750 12378 950","aria-hidden":"true"},c=a('<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D439" d="M48 1Q31 1 31 11Q31 13 34 25Q38 41 42 43T65 46Q92 46 125 49Q139 52 144 61Q146 66 215 342T285 622Q285 629 281 629Q273 632 228 634H197Q191 640 191 642T193 659Q197 676 203 680H742Q749 676 749 669Q749 664 736 557T722 447Q720 440 702 440H690Q683 445 683 453Q683 454 686 477T689 530Q689 560 682 579T663 610T626 626T575 633T503 634H480Q398 633 393 631Q388 629 386 623Q385 622 352 492L320 363H375Q378 363 398 363T426 364T448 367T472 374T489 386Q502 398 511 419T524 457T529 475Q532 480 548 480H560Q567 475 567 470Q567 467 536 339T502 207Q500 200 482 200H470Q463 206 463 212Q463 215 468 234T473 274Q473 303 453 310T364 317H309L277 190Q245 66 245 60Q245 46 334 46H359Q365 40 365 39T363 19Q359 6 353 0H336Q295 2 185 2Q120 2 86 2T48 1Z" style="stroke-width:3;"></path></g><g data-mml-node="mi" transform="translate(749,0)"><text data-variant="italic" transform="scale(1,-1)" font-size="884px" font-family="serif" font-style="italic">（</text></g><g data-mml-node="mi" transform="translate(1749,0)"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z" style="stroke-width:3;"></path></g><g data-mml-node="mi" transform="translate(2321,0)"><text data-variant="italic" transform="scale(1,-1)" font-size="884px" font-family="serif" font-style="italic">）</text></g><g data-mml-node="mi" transform="translate(3321,0)"><text data-variant="italic" transform="scale(1,-1)" font-size="884px" font-family="serif" font-style="italic">，</text></g><g data-mml-node="mi" transform="translate(4321,0)"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z" style="stroke-width:3;"></path></g><g data-mml-node="mo" transform="translate(5170.8,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z" style="stroke-width:3;"></path></g><g data-mml-node="mi" transform="translate(6226.6,0)"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z" style="stroke-width:3;"></path></g><g data-mml-node="mi" transform="translate(6587.6,0)"><path data-c="1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z" style="stroke-width:3;"></path></g><g data-mml-node="mi" transform="translate(7038.6,0)"><path data-c="1D462" d="M21 287Q21 295 30 318T55 370T99 420T158 442Q204 442 227 417T250 358Q250 340 216 246T182 105Q182 62 196 45T238 27T291 44T328 78L339 95Q341 99 377 247Q407 367 413 387T427 416Q444 431 463 431Q480 431 488 421T496 402L420 84Q419 79 419 68Q419 43 426 35T447 26Q469 29 482 57T512 145Q514 153 532 153Q551 153 551 144Q550 139 549 130T540 98T523 55T498 17T462 -8Q454 -10 438 -10Q372 -10 347 46Q345 45 336 36T318 21T296 6T267 -6T233 -11Q189 -11 155 7Q103 38 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z" style="stroke-width:3;"></path></g><g data-mml-node="mi" transform="translate(7610.6,0)"><path data-c="1D452" d="M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z" style="stroke-width:3;"></path></g><g data-mml-node="mo" transform="translate(8298.8,0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z" style="stroke-width:3;"></path></g><g data-mml-node="mi" transform="translate(9299,0)"><path data-c="1D45D" d="M23 287Q24 290 25 295T30 317T40 348T55 381T75 411T101 433T134 442Q209 442 230 378L240 387Q302 442 358 442Q423 442 460 395T497 281Q497 173 421 82T249 -10Q227 -10 210 -4Q199 1 187 11T168 28L161 36Q160 35 139 -51T118 -138Q118 -144 126 -145T163 -148H188Q194 -155 194 -157T191 -175Q188 -187 185 -190T172 -194Q170 -194 161 -194T127 -193T65 -192Q-5 -192 -24 -194H-32Q-39 -187 -39 -183Q-37 -156 -26 -148H-6Q28 -147 33 -136Q36 -130 94 103T155 350Q156 355 156 364Q156 405 131 405Q109 405 94 377T71 316T59 280Q57 278 43 278H29Q23 284 23 287ZM178 102Q200 26 252 26Q282 26 310 49T356 107Q374 141 392 215T411 325V331Q411 405 350 405Q339 405 328 402T306 393T286 380T269 365T254 350T243 336T235 326L232 322Q232 321 229 308T218 264T204 212Q178 106 178 102Z" style="stroke-width:3;"></path></g><g data-mml-node="mi" transform="translate(9802,0)"><path data-c="1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z" style="stroke-width:3;"></path></g><g data-mml-node="mi" transform="translate(10253,0)"><path data-c="1D452" d="M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z" style="stroke-width:3;"></path></g><g data-mml-node="mi" transform="translate(10719,0)"><path data-c="1D451" d="M366 683Q367 683 438 688T511 694Q523 694 523 686Q523 679 450 384T375 83T374 68Q374 26 402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487H491Q506 153 506 145Q506 140 503 129Q490 79 473 48T445 8T417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157Q33 205 53 255T101 341Q148 398 195 420T280 442Q336 442 364 400Q369 394 369 396Q370 400 396 505T424 616Q424 629 417 632T378 637H357Q351 643 351 645T353 664Q358 683 366 683ZM352 326Q329 405 277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q233 26 290 98L298 109L352 326Z" style="stroke-width:3;"></path></g><g data-mml-node="mi" transform="translate(11239,0)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z" style="stroke-width:3;"></path></g><g data-mml-node="mi" transform="translate(11584,0)"><path data-c="1D450" d="M34 159Q34 268 120 355T306 442Q362 442 394 418T427 355Q427 326 408 306T360 285Q341 285 330 295T319 325T330 359T352 380T366 386H367Q367 388 361 392T340 400T306 404Q276 404 249 390Q228 381 206 359Q162 315 142 235T121 119Q121 73 147 50Q169 26 205 26H209Q321 26 394 111Q403 121 406 121Q410 121 419 112T429 98T420 83T391 55T346 25T282 0T202 -11Q127 -11 81 37T34 159Z" style="stroke-width:3;"></path></g><g data-mml-node="mi" transform="translate(12017,0)"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z" style="stroke-width:3;"></path></g></g></g>',1),p=[c],_=t("mjx-assistive-mml",{unselectable:"on",display:"inline",style:{top:"0px",left:"0px",clip:"rect(1px, 1px, 1px, 1px)","-webkit-touch-callout":"none","-webkit-user-select":"none","-khtml-user-select":"none","-moz-user-select":"none","-ms-user-select":"none","user-select":"none",position:"absolute",padding:"1px 0px 0px 0px",border:"0px",display:"block",width:"auto",overflow:"hidden"}},[t("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[t("mi",null,"F"),t("mi",null,"（"),t("mi",null,"x"),t("mi",null,"）"),t("mi",null,"，"),t("mi",null,"x"),t("mo",null,"="),t("mi",null,"t"),t("mi",null,"r"),t("mi",null,"u"),t("mi",null,"e"),t("mo",null,"−"),t("mi",null,"p"),t("mi",null,"r"),t("mi",null,"e"),t("mi",null,"d"),t("mi",null,"i"),t("mi",null,"c"),t("mi",null,"t")])],-1),u=t("p",null,"这样通过一个函数我们就得到了一个具体的数值，这个数值的意义是：现在的输入数据经过一个拟合函数处理后得到的结果和真实结果的差距，梯度下降算法就是根据这个为基础进行对拟合函数中参数的优化。",-1),g=t("h3",{id:"梯度下降",tabindex:"-1"},[e("梯度下降 "),t("a",{class:"header-anchor",href:"#梯度下降","aria-label":'Permalink to "梯度下降"'},"​")],-1),f=t("p",null,[t("img",{src:"https://cdn.xyxsw.site/boxcnMuwaG2okodvywzbxX138Re.png",alt:""})],-1),x={class:"MathJax",jax:"SVG",style:{direction:"ltr",position:"relative"}},b={style:{overflow:"visible","min-height":"1px","min-width":"1px","vertical-align":"-0.464ex"},xmlns:"http://www.w3.org/2000/svg",width:"6.407ex",height:"2.351ex",role:"img",focusable:"false",viewBox:"0 -833.9 2832.1 1038.9","aria-hidden":"true"},w=a('<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D466" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z" style="stroke-width:3;"></path></g><g data-mml-node="mo" transform="translate(767.8,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z" style="stroke-width:3;"></path></g><g data-mml-node="msup" transform="translate(1823.6,0)"><g data-mml-node="mi"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z" style="stroke-width:3;"></path></g><g data-mml-node="mn" transform="translate(605,363) scale(0.707)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z" style="stroke-width:3;"></path></g></g></g></g>',1),y=[w],H=t("mjx-assistive-mml",{unselectable:"on",display:"inline",style:{top:"0px",left:"0px",clip:"rect(1px, 1px, 1px, 1px)","-webkit-touch-callout":"none","-webkit-user-select":"none","-khtml-user-select":"none","-moz-user-select":"none","-ms-user-select":"none","user-select":"none",position:"absolute",padding:"1px 0px 0px 0px",border:"0px",display:"block",width:"auto",overflow:"hidden"}},[t("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[t("mi",null,"y"),t("mo",null,"="),t("msup",null,[t("mi",null,"x"),t("mn",null,"2")])])],-1),k=a('<p><img src="https://cdn.xyxsw.site/boxcn83M9AW6xDm5pBIqmZEC6Kf.png" alt=""></p><p><img src="https://cdn.xyxsw.site/boxcneVFa131Lb9xDMCsIMI9fcc.png" alt=""></p><p>以此类推，我们最后的 w 在 0 的附近反复横跳，最后最接近目标函数的权重 w 就是 0。</p><h3 id="简单理解" tabindex="-1">简单理解 <a class="header-anchor" href="#简单理解" aria-label="Permalink to &quot;简单理解&quot;">​</a></h3><p>你可以简单这样理解：游戏中你在靶场练狙击枪，你用 4-8 倍镜瞄了 400 米的靶子，真实值就是靶心。你开了一枪后发现落在靶心上方，于是你根据距离靶心的远近，你的大脑开始计算优化下次瞄的位置，如果你往上面偏了很多，你就会将瞄点往下移动很多，如果往上偏了一点点，你就会将瞄点往下移动一点点。</p><p>移动的途中可能出现移动的过多的情况，从上偏变成下偏了，这就是如果学习率过大会出现的问题。</p><p>总而言之，你打狙击枪脑子怎么分析的，梯度下降算法就是怎么算的。当然由于它是电脑没有灵活的机动性，他的权重只能逐渐改变。</p><h1 id="关于-minist" tabindex="-1">关于 MINIST <a class="header-anchor" href="#关于-minist" aria-label="Permalink to &quot;关于 MINIST&quot;">​</a></h1><p><img src="https://cdn.xyxsw.site/boxcnxdyWA6Sj82kNxMlQ1b9hDg.png" alt=""></p><p>这个数据集可以说是最最经典的数据集了，里面有 0-9 这 10 个数字的手写图片和标注，正确率最高已经到了 99.7%.</p><h1 id="接下来干什么" tabindex="-1">接下来干什么？ <a class="header-anchor" href="#接下来干什么" aria-label="Permalink to &quot;接下来干什么？&quot;">​</a></h1><ul><li><strong>我想学 CV !!!!!!</strong></li></ul><p>你可以在 CV 模块中找到<a href="./4.6.5.3CV中的经典网络"> 4.6.5.3CV 中的经典网络</a> ，这里是一些最最经典的论文，我们推荐你阅读它们的原文并且复现它们的代码，这可以同时锻炼你的<strong> coding 能力和论文阅读能力</strong>，在阅读前，请参见<a href="./../1.杭电生存指南/1.10如何读论文">如何读论文</a> 。本模块的撰写者<strong> SRT 社团</strong>主要从事 CV 方向的研究，遇到问题欢迎与我们交流。（你都完成这些了不至于找不到我们的联系方式吧～）<strong>如果你读完了经典网络模块，你可以在它的最后找到接下来的学习路线～</strong></p><ul><li><strong>我想做<strong><strong> NLP</strong></strong> !!!!!!</strong></li></ul><p>NLP 研究方向庞大且复杂，若直接从 GPT 系列开始不免有些过于困难。我们建议你从了解 NLP 的任务开始，在有足够的基础后开始学习 RNN，LSTM 基准方法后向 <a href="./4.6.7Transformer">4.6.7Transformer</a> 进发 ，这个方法广泛运用在几乎所有深度学习领域，尤其是 NLP 的前沿研究已经无法离开 Transformer 了 hhhh。这个模块中我们也加入了一些 Transformer 的改进工作，包括 NLP，CV，和多模态</p><ul><li><strong>如果你想做多模态，对比学习等</strong>，请同时了解 CV 和 NLP 模块。这将是你后续知识的基础。多模态我们没有完善的讲义推出，对比学习可以参见<a href="./4.6.8对比学习"> 4.6.8 对比学习</a> 。这是撰写者之一的论文阅读笔记，不保证准确性与理解是否准确，可以作为论文阅读路线图来参考～</li></ul>',16);function P(M,q,L,V,D,S){const r=n("Bilibili");return Q(),T("div",null,[i,l(r,{bvid:"BV1P7411r7Dw"}),h,t("p",null,[e("首先我们需要有一个损失函数"),t("mjx-container",d,[(Q(),T("svg",m,p)),_])]),u,g,f,t("p",null,[e("假设损失函数为"),t("mjx-container",x,[(Q(),T("svg",b,y)),H]),e(", 梯度下降的目的是快速找到导数为 0 的位置（附近）")]),k])}const C=o(s,[["render",P]]);export{v as __pageData,C as default};
