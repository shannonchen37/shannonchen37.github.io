import{_ as a,o as t,c as e,U as s}from"./chunks/framework.489e5108.js";const u=JSON.parse('{"title":"定义正负样本的方式","description":"","frontmatter":{},"headers":[],"relativePath":"4.人工智能/4.6.8.3定义正负样本的方式.md","filePath":"4.人工智能/4.6.8.3定义正负样本的方式.md","lastUpdated":1696176798000}'),_={name:"4.人工智能/4.6.8.3定义正负样本的方式.md"},r=s('<h1 id="定义正负样本的方式" tabindex="-1">定义正负样本的方式 <a class="header-anchor" href="#定义正负样本的方式" aria-label="Permalink to &quot;定义正负样本的方式&quot;">​</a></h1><p>因为涉及多篇论文，就不具体一个个讲了，在这里总结一下一些定义正负样本的方式，这两种方式虽然本身并不突出，但是都对后续一些重要工作有一些铺垫作用。</p><h1 id="_1-时序性定义-生成式模型" tabindex="-1">1. 时序性定义（生成式模型） <a class="header-anchor" href="#_1-时序性定义-生成式模型" aria-label="Permalink to &quot;1.时序性定义（生成式模型）&quot;">​</a></h1><p><img src="https://cdn.xyxsw.site/boxcnC10uzdj0G0BJPlUZKFIi7C.png" alt=""></p><p>这是处理音频的一个例子，<strong>给模型 t 时刻以前的信息，让它抽取特征并对后文进行预测，真正的后文作为正样本，负样本当然是随便选取就好啦。</strong></p><p>不同于之前说的个体判别，这个是<strong>生成式模型</strong>，这个模型不止可以处理音频，还可以处理图片（每一个块换成一个词）或者处理图片（以 patch 为单位）。</p><p>是不是有点眼熟？这跟我前面写的 BERT 和 MAE 其实异曲同工，不过这两位是随机 mask，而非时序性的 mask。</p><h1 id="_2-以物体不同角度或者感官作为正样本" tabindex="-1">2. 以物体不同角度或者感官作为正样本 <a class="header-anchor" href="#_2-以物体不同角度或者感官作为正样本" aria-label="Permalink to &quot;2.以物体不同角度或者感官作为正样本&quot;">​</a></h1><p>一只狗可以被我们用不同感官所感受到，比如看见狗，听见狗叫声，摸到狗，得到文字描述等等。如果我们能统一这些模态的信息，这未尝不是一种特征提取。</p><p>这里就用了几个不同感官下的数据进行训练，不过可能是找配对的音频比较困难，作者用的是</p><p>原始图片，深度图，swav ace normal，分割图片这四个视角作为正样本，其他不相关图片作为负样本。</p><p>这种多视角的特征提取也引出了后面 CLIP 这篇论文，它做到了文本和图像特征的统一，我们后续再讲</p><p>（这篇论文我准备开个新坑放着了，因为说实话不算对比学习，算多模态）</p><p><img src="https://cdn.xyxsw.site/boxcnssaOVvp73SVIrzVvZPr1Je.png" alt=""></p>',14),o=[r];function p(n,c,i,d,l,h){return t(),e("div",null,o)}const x=a(_,[["render",p]]);export{u as __pageData,x as default};
